[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Data Analysis",
    "section": "",
    "text": "Everyone is a data analyst. The purpose of this book is to inspire and enable anyone who reads it to reconsider the methods they currently employ to analyse data. This is not to suggest that the methodologies outlined will be useful or sufficient for everyone who reads it. Some analyses can be performed quickly without the need for additional computation while others will require advanced analytics techniques not outlined in this book; however, the aspiration is that all will be equipped with novel tools and ideas for approaching data analysis."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "R for Data Analysis",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nNo prior knowledge is required to begin this book. The content will start at the very beginning by showing you how to set up your R environment and the basics of programming in R. By the end of the book, you will be able to perform intermediate analytics techniques such as linear regression and automatic report generation.\nYou will need an environment which you use to run your code. It is recommended that you download R and R Studio locally for this requirement. This book will walk you through how to do that as well as offer alternatives if that is not an option for you."
  },
  {
    "objectID": "index.html#structure-of-the-book",
    "href": "index.html#structure-of-the-book",
    "title": "R for Data Analysis",
    "section": "1.2 Structure of the Book",
    "text": "1.2 Structure of the Book\n\nPart I (Fundamentals) will introduce you to the basics of programming in the context of R.\nPart II (Data Acquisition) will teach you how to create, import, and access data.\nPart III (Data Preparation) will show you how to begin preparing your data for analysis.\nPart IV (Developing Insights) goes through the process of searching for and extracting insights from your data.\nPart V (Reporting) demonstrates how to wrap your analysis up by developing and automating reports.\n\nEach part will contain several chapters which cover specific ideas related to the overarching topic. At the end of each of these chapters you will find additional resources for you to use to dive deeper into the ideas. Each part will be concluded with practical exercises for you to test your skills.\nWhile sections of this book could be used to supplement formal education programs, it was initially designed to be used for independent study."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "R for Data Analysis",
    "section": "1.3 License",
    "text": "1.3 License\nThis work is free to use, and is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "R for Data Analysis",
    "section": "1.4 About Me",
    "text": "1.4 About Me\nI have an M.S. in Data Analytics, a B.S. in Business Analytics, and currently work in industry as an Analytics Manager for a software company. I began my journey into analytics by working as a Data Analyst for the university I was attending. This role allowed me to automate processes, build dashboards, deliver reports to executive stakeholders, and provide insight on how operations might be improved. I performed this role until I was promoted to lead the team. Later, I worked for a major CPG company driving pricing and promotion strategy for a large piece of the business.\nDespite my education, most of my basic analytics knowledge was hard-won through self-study. I created this resource to be what I wish I had when I started my journey into the analytics domain. Additionally, I don’t believe that one must be a domain expert to be effective at analyzing data. In fact, I think most people can quickly learn the skills necessary to be very effective at it.\nPhysical copies of this book are not currently available; however, you can download a pdf in the top left corner of this site. Feel free to contribute by reporting a typo or leaving a pull request at https://github.com/TrevorFrench/R-for-Data-Analysis.\n\n\n\n\nHofmann, J. R. 1996. Enlightenment and Electrodynamics. Cambridge University Press."
  },
  {
    "objectID": "p0c1-what-is-r.html#history",
    "href": "p0c1-what-is-r.html#history",
    "title": "1  What is R?",
    "section": "1.1 History",
    "text": "1.1 History\nR was built by Ross Ihaka and Robert Gentleman at the University of Auckland and was first released in 1993.\nRobert Gentleman and Ross Ihaka “both had an interest in statistical computing and saw a common need for a better software environment in [their] Macintosh teaching laboratory. [They] saw no suitable commercial environment and [they] began to experiment to see what might be involved in developing one [them]selves.” (Ihaka 1998)\nWhile R was officially first released in 1993, it wasn’t until 1995 that Ross Ihaka and Robert Gentlemann were convinced by Martin Mächler to release the source code freely (Ihaka 1998)."
  },
  {
    "objectID": "p0c1-what-is-r.html#resources",
    "href": "p0c1-what-is-r.html#resources",
    "title": "1  What is R?",
    "section": "1.2 Resources",
    "text": "1.2 Resources\n\nYou can learn more about R here: https://www.r-project.org/\nRead Ross Ihaka’s account of R’s origination: https://www.stat.auckland.ac.nz/~ihaka/downloads/Interface98.pdf\n“What is R?”” by Microsoft: https://mran.microsoft.com/documents/what-is-r\nR manuals by the R Development Core Team: https://cran.r-project.org/manuals.html\nR-bloggers: https://www.r-bloggers.com/\nR User Groups: https://www.meetup.com/pro/r-user-groups/\nR Studio Community: https://community.rstudio.com/\nThe R Journal: https://journal.r-project.org/\n\n\n\n\n\nHermans, Felienne. 2021. “Hadley Wickham on r and Tidyverse [Audio Podcast].” Software Engineering Radio. https://www.se-radio.net/2021/03/episode-450-hadley-wickham-on-r-and-tidyverse/.\n\n\nIhaka, Ross. 1998. “R : Past and Future History.” https://www.stat.auckland.ac.nz/~ihaka/downloads/Interface98.pdf."
  },
  {
    "objectID": "p0c2-what-is-data-analysis.html#the-process-of-data-analysis",
    "href": "p0c2-what-is-data-analysis.html#the-process-of-data-analysis",
    "title": "2  What is Data Analysis?",
    "section": "2.1 The Process of Data Analysis",
    "text": "2.1 The Process of Data Analysis\nThe process of data analysis can be generally described in five steps:\n\nGathering Requirements - Before one embarks on an analysis, it’s important to make sure the requirements are understood. Requirements include the questions your stakeholders are hoping to answer as well as the technical requirements of how you are going to perform your analysis.\nData Acquisition - As you might imagine, you must acquire your data before conducting an analysis. This may be done through methods such as manual creation of datasets, importing pre-constructed data, or leveraging APIs.\nData Preparation - Most data will not be received in the precise format you need to begin your analysis. The process of data preparation involves structuring and adding features to your data.\nDeveloping Insights - Once your data is prepared, you can begin to make sense of it and develop insights about its meaning.\nReporting - Finally, it’s important to report on your data in such a way that the information can be digested by the people who need to see it when they need to see it.\n\nOther sources may include additional steps such as “acting on the analysis”. While this is a critical step for organizations to capture the full value of their data, I would argue that it occurs outside of the analysis process.\nThis book will focus on the technical skills required to conduct an analysis. Because of this, we will be covering steps two through five and omitting step one."
  },
  {
    "objectID": "p0c2-what-is-data-analysis.html#resources",
    "href": "p0c2-what-is-data-analysis.html#resources",
    "title": "2  What is Data Analysis?",
    "section": "2.2 Resources",
    "text": "2.2 Resources\n\n“Data Science & Big Data Analytics: Discovering, Analyzing, Visualizing and Presenting Data” by EMC Education Services: https://onlinelibrary.wiley.com/doi/book/10.1002/9781119183686\n“Managing the Analytics Life Cycle for Decisions at Scale” by SAS: https://www.sas.com/content/dam/SAS/en_us/doc/whitepaper1/manage-analytical-life-cycle-continuous-innovation-106179.pdf\n\n\n\n\n\nEremenko, Kirill. 2020. “Hadley Wickham Talks Integration and Future of r and Python [Audio Podcast].” SuperDataScience. https://www.superdatascience.com/podcast/hadley-wickham-talks-integration-and-future-of-python-and-r."
  },
  {
    "objectID": "p0c3-setup.html#install-r",
    "href": "p0c3-setup.html#install-r",
    "title": "3  Setup",
    "section": "3.1 Install R",
    "text": "3.1 Install R\nBefore you do anything, you’ll need to download R. This download will allow your computer to interpret the R code you write later on.\n\nDownload R From R: The R Project for Statistical Computing\nSelect “download R”\n\n\n\n\n\n\n\nChoose any link but preferably the one closest to your physical location\n\n\n\n\n\n\n\nChoose your operating system\n\n\n\n\n\n\n\nPress “Install R for the first time”\n\n\n\n\n\n\n\nPress “download”\n\n\n\n\n\n\n\nOpen installer\n\n\n\n\n\n\n\nFollow the prompts and leave all options set as their default values"
  },
  {
    "objectID": "p0c3-setup.html#install-r-studio",
    "href": "p0c3-setup.html#install-r-studio",
    "title": "3  Setup",
    "section": "3.2 Install R Studio",
    "text": "3.2 Install R Studio\nAfter you install R, you’ll need an environment to write and run your code in. Most people use a program called “RStudio” for this. To download RStudio follow the steps listed below:\n\nNavigate to the R Studio download site: Download the RStudio IDE\nPress the “download” button under RStudio Desktop\n\n\n\n\n\n\n\nChoose the download option for your operating system\n\n\n\n\n\n\n\nOpen the installer and accept all defaults"
  },
  {
    "objectID": "p0c3-setup.html#alternatives",
    "href": "p0c3-setup.html#alternatives",
    "title": "3  Setup",
    "section": "3.3 Alternatives",
    "text": "3.3 Alternatives\n\n3.3.1 Posit Cloud\nPosit Cloud offers users a way to replicate the full RStudio experience without having to download or set anything up on your personal computer. You can sign up for a free account here: \n\n\n\n\n\n\n\n3.3.2 Replit\nReplit allows users to code in 50+ languages in the browser. While you won’t be able to follow along with the RStudio specific examples, you will be able to run R code. You can sign up for a free account here: \n\n\n\n\n\n\n\n3.3.3 Kaggle\nKaggle is one of the most popular sites for data analysts to compete in data competitions, find data, and discuss data topics. They also have a feature that allows you to write and run R (and Python) code. You can sign up for a free account here:"
  },
  {
    "objectID": "p0c3-setup.html#resources",
    "href": "p0c3-setup.html#resources",
    "title": "3  Setup",
    "section": "3.4 Resources",
    "text": "3.4 Resources\n\n“R Installation and Administration” by the R Core Team: https://cran.r-project.org/doc/manuals/r-release/R-admin.html"
  },
  {
    "objectID": "p1-fundamentals.html",
    "href": "p1-fundamentals.html",
    "title": "Part I: Fundamentals",
    "section": "",
    "text": "This section will introduce you to the basics of programming in the context of R. There are four chapters in this book. Each chapter has a brief description listed below. After you have finished reading through each of them, you will have the opportunity to attempt practical exercises to reinforce your newly-gained knowledge.\n\n\n\n\n\n\nNote\n\n\n\nUsers with a moderate amount of experience in R or another programming language should feel free to either skip, skim, or leverage this chapter as a reference guide.\n\n\n\nGetting Familiar with RStudio- There are four sections in RStudio. These sections are often referred to as “panes”. This chapter will introduce you to the “source”, “console”, “environment”, and “files” panes. Additionally, you will learn about the different ways you can customize your version of RStudio such as changing the color scheme.\nProgramming Basics- While the R language certainly has its unique advantages, it still leverages principles found in many other programming languages such as functions, comments, and loops. Learn how to apply these and other principles in R.\nData Types- Data is stored differently depending on what it represents when programming. For example, a number and a letter are stored as different data types. Learn about the five basic data types in R and how to use them.\nData Structures- In computer science, a data structure refers to the method which one uses to organize their data. Six basic data structures are commonly used in R. Learn about each of them in this chapter."
  },
  {
    "objectID": "p1c1-r-studio.html#customization",
    "href": "p1c1-r-studio.html#customization",
    "title": "4  Getting Familiar with RStudio",
    "section": "4.1 Customization",
    "text": "4.1 Customization\nYou are able to customize how your version of RStudio looks by following these steps:\n\nOpen RStudio and choose ‘tools’ from the toolbar\n\n\n\n\n\n\n\nChoose ‘Global Options’\n\n\n\n\n\n\n\nChoose ‘Appearance’ and select your favorite theme from the ‘Editor Theme’ section\n\n\n\n\n\n\n\nPress ‘Apply’\n\nThere are other customization options avaialable as well. Feel free to explore the “Global Options” section to make your version of RStudio your own."
  },
  {
    "objectID": "p1c1-r-studio.html#source-pane",
    "href": "p1c1-r-studio.html#source-pane",
    "title": "4  Getting Familiar with RStudio",
    "section": "4.2 Source Pane",
    "text": "4.2 Source Pane\nThe source pane is the top left pane in RStudio. This is where you will write and edit your code.\n\n\n\n\n\nIf you don’t see the source pane, you may need to create a new R script by pressing “Ctrl + Shift + N” (“Cmd + Shift + N” on Mac) or by selecting “R Script” from the “New File” dropdown in the top left corner.\n\n\n\n\n\nEach element of the source pane is outlined below.\n\n\n\n\n\n\nShow in New Window- This allows you to pop the source pane into a new window by itself.\nSave Current Document- This saves the file contained in the tab you currently have active.\nSource on Save- Automatically sources your file every time you hit save. “Sourcing” is similar to “Running” in the sense that both will execute your code; however, sourcing will execute your saved file rather than copying lines of code into the console.\nFind/Replace- this feature allows you to find and replace specified text, similar to find and replace features in other tools such as Excel.\nCode Tools- This brings up a menu of options which help you to code more efficiently. Some of these tools include formatting your code and help with function definitions.\nCompile Report- This allows you to compile a report directly from an R script without needing to use additional frameworks such as R Markdown.\nRun Current Selection- This allows you to highlight a portion of your code and run only that portion.\nRe-run Previous Code Region- This option will execute the last section of code that you ran.\nGo to Previous/Next Section/Chunk- These up and down arrows allow you to navigate through sections of your code without needing to scroll.\nSource Contents- This option will save your active document if it isn’t already saved and then source the file.\nOutline- Pressing this option will pop open an outline of your current file.\nAdjust Frame Size- These two options will adjust the size of the source pane inside of R Studio.\nSyntax Highlighting- This allows you to adjust the syntax highlighting of your active document to match the highlighting of other file types.\n“Jump To” Menu- This menu allows you to quickly jump to different sections of your code.\nCursor Position- This displays your current cursor position by row and column.\nRow Numbers- Display the row number for each line of your code on the left side of the document.\nBack/Forward- These arrows are navigation tools that will allow you to redo/undo the following actions: opening a document (or switching tabs), going to a function definition, jumping to a line, and jumping to a function using the function menu (Paulson 2022).\nTab- This is a tab in the traditional sense, meaning you are able to have a collection of documents open displayed as tabs. These tabs will have the title of your document and often an icon of some sort to demonstrate the file type."
  },
  {
    "objectID": "p1c1-r-studio.html#console",
    "href": "p1c1-r-studio.html#console",
    "title": "4  Getting Familiar with RStudio",
    "section": "4.3 Console",
    "text": "4.3 Console\nThe console pane is the bottom left pane in RStudio. This pane has three tabs: “Console”, “Terminal”, and “Background Jobs”.\n\nThe “Console” tab is where you will be able to run R code directly without writing a script (this will be covered in the next chapter).\nThe “Terminal” tab is the same terminal you have on your computer. This can be adjusted in the global options.\nThe “Background Jobs” tab is where you can start and manage processes that need to run behind the scenes."
  },
  {
    "objectID": "p1c1-r-studio.html#environment",
    "href": "p1c1-r-studio.html#environment",
    "title": "4  Getting Familiar with RStudio",
    "section": "4.4 Environment",
    "text": "4.4 Environment\nThe environment pane is the top right pane in RStudio. This is where you will manage all things related to your development environment. This pane has four tabs: “Environment”, “History”, “Connections”, and “Tutorial”.\n\nThe “Environment” tab will display all information relevant to your current environment. This includes data, variables, and functions. This is also the place where you can view and manage your memory usage as well as your workspace.\nThe “History” tab allows you to view the history of your executed code. You can search through these commands and even select and re-execute them.\nThe “Connections” tab is where you can create and manage connections to databases.\nThe “Tutorial” tab delivers tutorials powered by the “learnr” package."
  },
  {
    "objectID": "p1c1-r-studio.html#files",
    "href": "p1c1-r-studio.html#files",
    "title": "4  Getting Familiar with RStudio",
    "section": "4.5 Files",
    "text": "4.5 Files\nThe files pane is the bottom right pane in RStudio. This pane has six tabs: “Files”, “Plots”, “Packages”, “Help”, “Viewer”, and “Presentation”.\n\nThe “Files” tab is a file explorer of sorts. You can view the contents of a directory, navigate to new directories, and manage files here.\nThe “Plots” tab is where the output of your generated plots will show up. You can also export your plots from this tab.\nThe “Packages” tab allows you to view all available packages within your environment. From this tab, you can read more about each package as well as update and access packages.\nThe “Help” tab allows you to search for information about functions to include examples, descriptions, and available parameters.\nThe “Viewer” tab is where certain types of content such as quarto documents will be displayed when rendered.\nThe “Presentation” tab is similar to the “Viewer” tab except the content type will be presentations."
  },
  {
    "objectID": "p1c1-r-studio.html#resources",
    "href": "p1c1-r-studio.html#resources",
    "title": "4  Getting Familiar with RStudio",
    "section": "4.6 Resources",
    "text": "4.6 Resources\n\n“Editing and Executing Code in the RStudio IDE” from the R Studio Support team: https://support.rstudio.com/hc/en-us/articles/200484448-Editing-and-Executing-Code\n“Code Folding and Sections in the RStudio IDE” from the R Studio Support team: https://support.rstudio.com/hc/en-us/articles/200484568-Code-Folding-and-Sections-in-the-RStudio-IDE\n“Keyboard Shortcuts in the RStudio IDE” from the R Studio Support team: https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts-in-the-RStudio-IDE\n“Navigating Code in the RStudio IDE” from the R Studio Support team: https://support.rstudio.com/hc/en-us/articles/200710523-Navigating-Code-in-the-RStudio-IDE\n\n\n\n\n\nPaulson, Josh. 2022. Navigating Code in the RStudio IDE. https://support.rstudio.com/hc/en-us/articles/200710523-Navigating-Code-in-the-RStudio-IDE."
  },
  {
    "objectID": "p1c2-programming-basics.html#executing-code",
    "href": "p1c2-programming-basics.html#executing-code",
    "title": "5  Programming Basics",
    "section": "5.1 Executing Code",
    "text": "5.1 Executing Code\nWhen working in most programming languages, you will generally have the option to execute code one of two ways:\n\nin the console\nin a script\n\n\n5.1.1 Console\nThe first way to run code is directly in the console. If you’re working in RStudio, you will access the console through the “console” pane.\nAlternatively, if you downloaded R to your personal computer, you will likely be able to search your machine for an app named “RGui” and access the console this way as well.\n\n\n\n\n\nIn the following example, the text “print(3+2)”” is typed into the console. The user then presses enter and sees the result: “[1] 5”.\n\nprint(3+2)\n\n[1] 5\n\n\nYou may be wondering what “[1]” represents. This is simply a line number in the console and can be ignored for most practical purposes. Additionally, most of the examples in this book will be structured in this way: formatted code immediately followed by the code output.\n\n\n5.1.2 Script\nYou likely will be using scripts most of the time when working in R. A script is just a file that allows you to type out longer sequences of code and execute them all at once.\nFor those of you following along in RStudio, you can create a script by pressing “Ctrl + Shift + N” on Windows or by selecting “R Script” from the “New File” dropdown in the top left corner.\n\n\n\n\n\nFrom here you can type the same command from before into the source pane. Next, you’ll want to save your file by pressing “Ctrl + S” on Windows or by selecting “Save” from the “File” dropdown in the top left corner. Now just give your file a name and your file will automatically be saved as a “.R” file.\nFinally, run your newly created R script by pressing the “source” button."
  },
  {
    "objectID": "p1c2-programming-basics.html#comments",
    "href": "p1c2-programming-basics.html#comments",
    "title": "5  Programming Basics",
    "section": "5.2 Comments",
    "text": "5.2 Comments\nComments are present in most (if not all) programming languages. They allow the user to write text in their code that isn’t executed or read by computers. Comments can serve many purposes such as notes, instructions, or formatting.\nComments are created in R by using the “#” symbol. Here’s an example:\n\n# This is a comment\nprint(3+2)\n\n[1] 5\n\n\nSome programming languages allow you a “bulk-comment” feature which allows you to quickly comment out multiple consecutive lines of text. However, in R, there is no such option. Each line must begin with a “#” symbol, as such:\n\n# This is the first line of a comment\n# This is the second line of a comment\nprint(3+2)\n\n[1] 5\n\n\nComments don’t have to start at the beginning of a line. You are able to start comments anywhere on a line like in this example:\n\nprint(3+2) # This comment starts mid-line\n\n[1] 5"
  },
  {
    "objectID": "p1c2-programming-basics.html#variables",
    "href": "p1c2-programming-basics.html#variables",
    "title": "5  Programming Basics",
    "section": "5.3 Variables",
    "text": "5.3 Variables\nVariables are used in programming to give values to a symbol. In the following example we have a variable named “rate” which is equal to 15, a variable named “hours” which is equal to 4, and a variable named “total_cost” which is equal to rate * hours.\n\nrate <- 15\nhours <- 4\ntotal_cost <- rate * hours\nprint(total_cost)\n\n[1] 60"
  },
  {
    "objectID": "p1c2-programming-basics.html#operators",
    "href": "p1c2-programming-basics.html#operators",
    "title": "5  Programming Basics",
    "section": "5.4 Operators",
    "text": "5.4 Operators\nAn operator is a symbol that allows you to perform an action or define some sort of logic. The following image demonstrates the operators that are available to you in R.\n\n\n\n\n\n\n5.4.1 Arithmetic Operators\nArithmetic operators allow users to perform basic mathematical operations. The examples below demonstrate how these operators might be used. For those not familiar, the modulus operator will return the remainder of a division operation while integer (or Euclidean) division returns the result of a division operation without the fractional component.\n\n3 + 3\n\n[1] 6\n\n3 - 3\n\n[1] 0\n\n3 * 3\n\n[1] 9\n\n3 ^ 3\n\n[1] 27\n\n10 / 7\n\n[1] 1.428571\n\n10 %% 7\n\n[1] 3\n\n10 %/% 7\n\n[1] 1\n\n\n\n\n5.4.2 Comparison Operators\nComparison operators allow users to compare values. The examples below demonstrate how these operators might be used.\n\n3 == 3\n\n[1] TRUE\n\n3 != 3\n\n[1] FALSE\n\n3 > 3\n\n[1] FALSE\n\n3 < 3\n\n[1] FALSE\n\n3 >= 3\n\n[1] TRUE\n\n3 <= 3\n\n[1] TRUE\n\n\n\n\n5.4.3 Logical Operators\nLogical operators allow users to express “AND”, “OR”, and “NOT”. The following examples demonstrate how these operators might be used in conjunction with comparison operators as well as the difference between standard logical operators and “vectorized” logical operators.\nIn this example, we will evaluate two vectors of the same length from left to right. Each vector has seven observations (-3, -2, -1, 0, 1, 2, 3). Rather than simply returning a single “TRUE” or “FALSE”, this will return seven “TRUE” or “FALSE” values. In this case, the first element of each vector (“-3” and “-3”) will be evaluated against their respective conditions and return “TRUE” only if both conditions are met. This will then be repeated for each of the remaining elements.\n\n# Vectorized \"AND\" operator\n((-3:3) >= 0) & ((-3:3) <= 0)\n\n[1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n\n\nThis example will return a single “TRUE” only if both conditions are met, otherwise “FALSE” will be returned.\n\n# Standard \"AND\" operator\n(3 >= 0) && (-3 <= 0)\n\n[1] TRUE\n\n\nThis example is the same as the previous one with the exception that we have negated the second condition with a “NOT” operator.\n\n# Standard \"AND\" operator with \"NOT\" operator\n(3 >= 0) && !(-3 <= 0)\n\n[1] FALSE\n\n\nThe following two examples are essentially the same as the first two except that we are using “OR” operators rather than “AND” operators\n\n# Vectorized \"OR\" operator\n((-3:3) >= 0) | ((-3:3) <= 0)\n\n[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n# Standard \"OR\" operator\n(3 >= 0) || (-3 <= 0)\n\n[1] TRUE\n\n\n\n\n5.4.4 Assignment Operators\nAssignment operators allow users to assign values to something. For most users, only “<-” or “->” will ever be used. These are called local assignment operators. However, there is another type of operator called a global assignment operator which is denoted by “<<-” or “->>”.\nUnderstanding the difference between local and global assignment operators in R can be tricky to get your head around. Here’s an example which should clear things up.\nFirst, let’s create two variables named “global_var” and “local_var” and give them the values “global” and “local”, respectively. Notice we are using the standard assignment operator “<-” for both variables.\n\nglobal_var <- 'global'\nlocal_var <- 'local'\n\nglobal_var\n\n[1] \"global\"\n\nlocal_var\n\n[1] \"local\"\n\n\nNext, let’s create a function to test out the global assignment operator (“<<-”). Inside this function, we will assign a new value to both of the variables we just created; however, we will use the “<-” operator for the local_var and the “<<-” operator for the global_var so that we can observe the difference in behavior.\n\n\n\n\n\n\nNote\n\n\n\nFunctions are covered directly after this section. If the concept of functions is unfamiliar to you, feel free to jump ahead and come back later.\n\n\n\nmy_function <- function() {\n   global_var <<- 'na'\n   local_var <- 'na'\n   print(global_var)\n   print(local_var)\n}\n\nmy_function()\n\n[1] \"na\"\n[1] \"na\"\n\n\nThis function performs how you would expect it to intuitively, right? The interesting part comes next when we print out the values of these variables again.\n\nglobal_var\n\n[1] \"na\"\n\nlocal_var\n\n[1] \"local\"\n\n\nFrom this result, we can see the difference in behavior caused by the differing assignment operators. When using the “<-” operator inside the function, it’s scope is limited to just the function that it lives in. On the other hand, the “<<-” operator has the ability to edit the value of the variable outside of the function as well.\nYou may now be wondering why both the local and the global assignment operators have two separate denotations. The following example demonstrates the difference between the two.\n\nx <- 3\n3 -> y\n\nx\n\n[1] 3\n\ny\n\n[1] 3\n\n\nThere is also a third assignment operator that can be used: “=”. You will generally use the local assignment operator; however, you may notice that the “=” operator is used within certain functions as you progress. You can find more information about these three operators in the resources section.\n\n\n5.4.5 Miscellaneous Operators\nThe “:” operator allows users to create a series of numbers in a sequence. This was demonstrated in the logical operator section. The %in% operator checks if an element exists in a vector. Both of these operators are demonstrated in the following example.\n\n3 %in% 1:3\n\n[1] TRUE\n\n\nFinally, the “%*%” operator allows users to perform matrix multiplication as is demonstrated below. First, let’s create a 2x2 matrix and then let’s multiply it by itself.\n\nx <- matrix(\n  c(1,3,3,7)\n  , nrow = 2\n  , ncol = 2\n  , byrow = TRUE)\n\nx %*% x\n\n     [,1] [,2]\n[1,]   10   24\n[2,]   24   58"
  },
  {
    "objectID": "p1c2-programming-basics.html#functions",
    "href": "p1c2-programming-basics.html#functions",
    "title": "5  Programming Basics",
    "section": "5.5 Functions",
    "text": "5.5 Functions\nFunctions allow you to bundle a predefined set of operations into one command. The syntax of functions in R is as follows.\n\n# Create a function called function_name\nfunction_name <- function() {\n  print(\"Hello World!\")\n}\n\n# Call your newly created function\nfunction_name()\n\n[1] \"Hello World!\"\n\n\nTo go one step further, you can also add “arguments” to a function. Arguments allow you to pass information into the function when it is called. Here’s an example:\n\n# Create a function called add_numbers which will add \n# two specified numbers together and print the result\nadd_numbers <- function(x, y) {\n    print(x + y)\n}\n\n# Call your newly created function twice with different inputs\nadd_numbers(2, 3)\n\n[1] 5\n\nadd_numbers(50, 50)\n\n[1] 100\n\n\nFinally, you can return a value from a function as such:\n\n# Create a function called calculate_raise which multiplies \n# base_salary and annual_adjustment and returns the result\ncalculate_raise <- function(base_salary, annual_adjustment) {\n    raise <- base_salary * annual_adjustment\n    return(raise)\n}\n\n# Calculate John's raise\njohns_raise <- calculate_raise(90000, .05)\n\n#Calculate Jane's raise\njanes_raise <- calculate_raise(100000, .045)\n\nprint(\"John's Raise:\")\n\n[1] \"John's Raise:\"\n\nprint(johns_raise)\n\n[1] 4500\n\nprint(\"Jane's Raise:\")\n\n[1] \"Jane's Raise:\"\n\nprint(janes_raise)\n\n[1] 4500"
  },
  {
    "objectID": "p1c2-programming-basics.html#loops",
    "href": "p1c2-programming-basics.html#loops",
    "title": "5  Programming Basics",
    "section": "5.6 Loops",
    "text": "5.6 Loops\nThere are two types of loops in R: while loops and for loops.\n\n5.6.1 While Loops\nWhile loops are executed as follows:\n\n# Set i equal to 1\ni <- 1\n\n# While i is less than or equal to three, print i\n# The loop will increment the value of i after each print\nwhile (i <= 3) {\n  print(i)\n  i <- i + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n\n\nAdditionally, you can add ‘break’ statements to while loops to stop the loop early.\n\ni <- 1\n\nwhile (i <= 10) {\n    print(i)\n    if (i == 5) {\n        print(\"Stopping halfway\")\n        break\n    }\n    i <- i + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] \"Stopping halfway\"\n\n\n\n\n5.6.2 For Loops\nFor loops are executed as follows:\n\nemployees <- list(\"jane\", \"john\")\n\nfor (employee in employees) {\n  print(employee)\n}\n\n[1] \"jane\"\n[1] \"john\""
  },
  {
    "objectID": "p1c2-programming-basics.html#conditionals",
    "href": "p1c2-programming-basics.html#conditionals",
    "title": "5  Programming Basics",
    "section": "5.7 Conditionals",
    "text": "5.7 Conditionals\nYou are also able to execute a command if a condition is met by using “if” statements.\n\nif (2 > 0) {\n    print(\"true\")\n}\n\n[1] \"true\"\n\n\nYou can add more conditions by adding “else if” statements.\n\nif (2 > 3) {\n    print(\"two is greater than three\")\n} else if (2 < 3) {\n    print(\"two is not greater than three\")\n}\n\n[1] \"two is not greater than three\"\n\n\nFinally, you can catch anything that doesn’t meet any of your conditions by adding an “else” statement at the end.\n\nx <- 20\nif (x < 20) {\n    print(\"x is less than 20\")\n} else if (x > 20) {\n    print(\"x is greater than 20\")\n} else {\n    print(\"x is equal to 20\")\n}\n\n[1] \"x is equal to 20\""
  },
  {
    "objectID": "p1c2-programming-basics.html#r-packages",
    "href": "p1c2-programming-basics.html#r-packages",
    "title": "5  Programming Basics",
    "section": "5.8 R packages",
    "text": "5.8 R packages\nPackages allow you to access functions other people have created and shared in a standard format, e.g. via the Comprehensive R Archive Network (CRAN), Bioconductor, the r-universe or e.g. as github repositories.\nTo access a package’s functionality, you first have to add it to your system’s library. Afterward, you can check it out for use in your current session with the library() command.\nIn this example, we will be installing and loading a common package named “dplyr”.\nYou first retrieve it from CRAN with the following command.\n\ninstall.packages(\"dplyr\")\n\nNext, you make it available in your R session with the library() command. (Alternatively, you can also use the require() command.)\n\nlibrary(dplyr)\n\nYou are now able to access all of the functions available in the dplyr library!\nSometimes users in the R community create their own packages that aren’t distributed through the CRAN network. You can still use these packages, but you’ll just have to perform an extra step or two. One of the most common places to host packages is Github. The following example will demonstrate how to load a package that I created from Github.\nFirst you’ll need to install the “remotes” package. As the name might suggest, this package allows you to access other packages from remote locations.\n\ninstall.packages(\"remotes\")\n\nNext you’ll need to install the remote package of your choosing. In our case, we’ll execute the following code.\n\nremotes::install_github(\"TrevorFrench/trevoR\")\n\nIn the previous example, we used the “install_github” function from the “remotes” package and then specified the Github path of the remote repository by typing “TrevorFrench/trevoR”. This code is functionally the same as the “install.packages” function. You may have noticed a new piece of syntax though. The “::” in between “remotes” and “install_github” tells R to use the “install_github” function from the “remotes” library without the need to require the library via the “library” function. This syntax can be used with any other function from any other library.\nNow that the remote package is installed, we can require it in the same way we would any other package.\n\nlibrary(trevoR)"
  },
  {
    "objectID": "p1c2-programming-basics.html#resources",
    "href": "p1c2-programming-basics.html#resources",
    "title": "5  Programming Basics",
    "section": "5.9 Resources",
    "text": "5.9 Resources\n\nW3 Schools R Tutorial: https://www.w3schools.com/r/\nAssignment Operators: https://stat.ethz.ch/R-manual/R-devel/library/base/html/assignOps.html"
  },
  {
    "objectID": "p1c3-data-types.html#numeric",
    "href": "p1c3-data-types.html#numeric",
    "title": "6  Data Types",
    "section": "6.1 Numeric",
    "text": "6.1 Numeric\n\n6.1.1 Double\nLet’s explore the “double” data type by assigning a number to a variable and then check its type by using the “typeof” function. Alternatively, we can use the “is.double” function to check whether or not the variable is a double.\n\nx <- 6.2\ntypeof(x)\n\n[1] \"double\"\n\nis.double(x)\n\n[1] TRUE\n\n\nNext, let’s check whether or not the variable is numeric by using the “is.numeric” function.\n\nis.numeric(x)\n\n[1] TRUE\n\n\nThis function should return “TRUE” as well, which demonstrates the fact that a double is a subset of the numeric data type.\n\n\n6.1.2 Integer\nLet’s explore the “integer” data type by assigning a whole number followed by the capital letter “L” to a variable and then check its type by using the “typeof” function. Alternatively, we can use the “is.integer” function to check whether or not the variable is an integer.\n\nx <- 6L\n# By using the \"typeof\" function, we can check the data type of x\ntypeof(x)\n\n[1] \"integer\"\n\nis.integer(x)\n\n[1] TRUE\n\n\nNext, let’s check whether or not the variable is numeric by using the “is.numeric” function.\n\nis.numeric(x)\n\n[1] TRUE\n\n\nThis function should return “TRUE” as well, demonstrating that an integer is also a subset of the numeric data type."
  },
  {
    "objectID": "p1c3-data-types.html#complex",
    "href": "p1c3-data-types.html#complex",
    "title": "6  Data Types",
    "section": "6.2 Complex",
    "text": "6.2 Complex\nComplex data types make use of the mathematical concept of an imaginary number through the use of the lowercase letter “i”. The following example sets “x” equal to six times i and then displays the type of x.\n\nx <- 6i\ntypeof(x)\n\n[1] \"complex\""
  },
  {
    "objectID": "p1c3-data-types.html#character",
    "href": "p1c3-data-types.html#character",
    "title": "6  Data Types",
    "section": "6.3 Character",
    "text": "6.3 Character\nCharacter data types store text data. When creating characters, make sure you wrap your text in quotation marks.\n\nx <- \"Hello!\"\ntypeof(x)\n\n[1] \"character\""
  },
  {
    "objectID": "p1c3-data-types.html#logical",
    "href": "p1c3-data-types.html#logical",
    "title": "6  Data Types",
    "section": "6.4 Logical",
    "text": "6.4 Logical\nLogical data types store either “TRUE” or “FALSE”. Unlike characters, these data should not be wrapped in quotation marks.\n\nx <- TRUE\ntypeof(x)\n\n[1] \"logical\""
  },
  {
    "objectID": "p1c3-data-types.html#raw",
    "href": "p1c3-data-types.html#raw",
    "title": "6  Data Types",
    "section": "6.5 Raw",
    "text": "6.5 Raw\nUsed less often, the raw data type will store data as raw bytes. You can convert character data types to raw data types by using the “charToRaw” function. Similarly, you can convert integer data types to raw data types through the use of the “intToBits” function.\n\nx <- charToRaw(\"Hello!\")\nprint(x)\n\n[1] 48 65 6c 6c 6f 21\n\ntypeof(x)\n\n[1] \"raw\"\n\nx <- intToBits(6L)\nprint(x)\n\n [1] 00 01 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\n[26] 00 00 00 00 00 00 00\n\ntypeof(x)\n\n[1] \"raw\""
  },
  {
    "objectID": "p1c3-data-types.html#resources",
    "href": "p1c3-data-types.html#resources",
    "title": "6  Data Types",
    "section": "6.6 Resources",
    "text": "6.6 Resources\n\nW3 Schools: https://www.w3schools.com/r/r_data_types.asp\n“Advanced R” by Hadley Wickham: https://adv-r.hadley.nz/vectors-chap.html#atomic-vectors\n“Bits and Bytes” from Stanford CS 101: https://web.stanford.edu/class/cs101/bits-bytes.html"
  },
  {
    "objectID": "p1c4-data-structures.html#vectors",
    "href": "p1c4-data-structures.html#vectors",
    "title": "7  Data Structure",
    "section": "7.1 Vectors",
    "text": "7.1 Vectors\nWe can create a vector by using the “c” function to combine multiple values into a single vector. In the following example, we will combine four separate numbers into a single vector and the output the resulting vector to see what it looks like.\n\nx <- c(1, 3, 3, 7)\n\nprint(x)\n\n[1] 1 3 3 7"
  },
  {
    "objectID": "p1c4-data-structures.html#lists",
    "href": "p1c4-data-structures.html#lists",
    "title": "7  Data Structure",
    "section": "7.2 Lists",
    "text": "7.2 Lists\nLists are a collection of objects. This means that each element can be a different data type (unlike vectors). In the following example we’ll create a list containing two character objects and one vector with the “list” function.\n\nfirst_name <- \"John\"\nlast_name <- \"Smith\"\nfavorite_numbers <- c(1, 3, 3, 7)\n\nperson <- list(first_name, last_name, favorite_numbers)\n\nprint(person)\n\n[[1]]\n[1] \"John\"\n\n[[2]]\n[1] \"Smith\"\n\n[[3]]\n[1] 1 3 3 7"
  },
  {
    "objectID": "p1c4-data-structures.html#matrices",
    "href": "p1c4-data-structures.html#matrices",
    "title": "7  Data Structure",
    "section": "7.3 Matrices",
    "text": "7.3 Matrices\nA matrix is a two-dimensional array where the data is all of the same type. In the following example, we’ll create a matrix with three rows and four columns.\n\nx <- matrix(\n        c(1,3,3,7,1,3,3,7,1,3,3,7)\n        , nrow = 3\n        , ncol = 4\n        , byrow = TRUE)\n\nprint(x)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    3    7\n[2,]    1    3    3    7\n[3,]    1    3    3    7"
  },
  {
    "objectID": "p1c4-data-structures.html#factors",
    "href": "p1c4-data-structures.html#factors",
    "title": "7  Data Structure",
    "section": "7.4 Factors",
    "text": "7.4 Factors\nFactors are used to designate levels within categorical data. In the following example, we’ll use the “factor” function on a vector of assorted color names to receive the “levels” which it contains.\n\nx <- c(\"Red\", \"Blue\", \"Red\", \"Yellow\", \"Yellow\")\n\ncolors <- factor(x)\n\nprint(colors)\n\n[1] Red    Blue   Red    Yellow Yellow\nLevels: Blue Red Yellow"
  },
  {
    "objectID": "p1c4-data-structures.html#data-frames",
    "href": "p1c4-data-structures.html#data-frames",
    "title": "7  Data Structure",
    "section": "7.5 Data Frames",
    "text": "7.5 Data Frames\nA data frame contains two-dimensional data. Unlike the matrix data structure, each column of a data frame can contain data of a differing type (but within a column the data must be of the same type). The following example will create a data frame with two rows and two columns.\n\npeople <- c(\"John\", \"Jane\")\nid <- c(1, 2)\ndf <- data.frame(id = id, person = people)\n\nprint(df)\n\n  id person\n1  1   John\n2  2   Jane"
  },
  {
    "objectID": "p1c4-data-structures.html#arrays",
    "href": "p1c4-data-structures.html#arrays",
    "title": "7  Data Structure",
    "section": "7.6 Arrays",
    "text": "7.6 Arrays\nArrays are objects that can have more than two dimensions. This is sometimes referred to as being “n-dimensional”. The dimensions of the following example are 1 x 4 x 3. You’ll see that the data consist of one row and four columns spread out over a third dimension.\n\nx <- array(\n        c(1,3,3,7,1,3,3,7,1,3,3,7)\n        , dim = c(1,4,3))\n\nprint(x)\n\n, , 1\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    3    7\n\n, , 2\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    3    7\n\n, , 3\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    3    7"
  },
  {
    "objectID": "p1c4-data-structures.html#resources",
    "href": "p1c4-data-structures.html#resources",
    "title": "7  Data Structure",
    "section": "7.7 Resources",
    "text": "7.7 Resources\n\nW3 Schools: https://www.w3schools.com/r/r_vectors.asp"
  },
  {
    "objectID": "p1exercises.html#questions",
    "href": "p1exercises.html#questions",
    "title": "Exercises",
    "section": "Questions",
    "text": "Questions\n\n\n\n\n\n\nExercise: 5-A\n\n\n\nWrite a function called “multiply” that accepts two numbers as arguments and outputs the product of those two numbers when called as is demonstrated below.\nmultiply(3, 3)\n# [1] 9\n\n\n\n\n\n\n\n\nExercise: 5-B\n\n\n\nWrite an equation that returns the remainder of 12 divided by 8.\n\n\n\n\n\n\n\n\nExercise: 5-C\n\n\n\nWrite an equation that returns the remainder of 36 divided by 10.\n\n\n\n\n\n\n\n\nExercise: 5-D\n\n\n\nWrite a “while” loop that prints all even numbers from 0 to 10.\nIt’s possible for this task to be accomplished in several ways; however, the output of your program should always look like this:\n# [1] 0\n# [1] 2\n# [1] 4\n# [1] 6\n# [1] 8\n# [1] 10\n\n\n\n\n\n\n\n\nExercise: 5-E\n\n\n\nYou are given a vector that looks like this:\nnumbers <- c(0:12)\nWrite a for loop that loops through your vector and prints any element greater than or equal to 3.\nIt’s possible for this task to be accomplished in several ways; however, the output of your program should always look like this:\n# [1] 3\n# [1] 4\n# [1] 5\n# [1] 6\n# [1] 7\n# [1] 8\n# [1] 9\n# [1] 10\n# [1] 11\n# [1] 12\n\n\n\n\n\n\n\n\nExercise: 6-A\n\n\n\nConvert the following character variable to a variable with the data type “raw”:\nx <- \"Trevor rocks\"\nYou should store your raw data in a variable named “raw_data”, print the data to the console, and check the data type with the “typeof” function. Your output should look like the following:\nprint(raw_data)\n# [1] 54 72 65 76 6f 72 20 72 6f 63 6b 73\ntypeof(raw_data)\n# [1] \"raw\"\n\n\n\n\n\n\n\n\nExercise: 6-B\n\n\n\nCreate a variable named “spending” and give it a value of 120. Then create a variable named “budget” and give it a value of 100. Next, check whether spending is greater than budget and store the resulting logical data in a variable named “over_budget”. Finally, print the value of “over_budget” variable and check it’s data type with the “typeof” function.\nYour final output should look like this:\nprint(over_budget)\n# [1] TRUE\ntypeof(over_budget)\n# [1] \"logical\"\n\n\n\n\n\n\n\n\nExercise: 7-A\n\n\n\nCreate a vector named “animal” and give it the following three values: “cow”, “cat”, “pig”. Create a second vector named “sound” and give it the following three values: “moo”, “meow”, “oink”. Finally, create a data frame named “animal_sounds” and assign each of these vectors to be a column.\nAfter printing the resulting data frame to the console, you should get the following output:\n#   animal sound\n# 1    cow   moo\n# 2    cat  meow\n# 3    pig  oink"
  },
  {
    "objectID": "p1exercises.html#answers",
    "href": "p1exercises.html#answers",
    "title": "Exercises",
    "section": "Answers",
    "text": "Answers\n\n\n\n\n\n\nAnswer: 5-A\n\n\n\nOne way you could accomplish this task is demonstrated in the following solution.\n\nmultiply <- function(x, y) {\n  return (x * y)\n}\n\nmultiply(3, 3)\n\n[1] 9\n\n\n\n\n\n\n\n\n\n\nAnswer: 5-B\n\n\n\nA remainder is referred to as “modulus” in programming. We can use the “%%” operator to accomplish this. For this example, the output of your equation should be 4.\n\n12 %% 8\n\n[1] 4\n\n\n\n\n\n\n\n\n\n\nAnswer: 5-C\n\n\n\nA remainder is referred to as “modulus” in programming. We can use the “%%” operator to accomplish this. For this example, the output of your equation should be 6.\n\n36 %% 10\n\n[1] 6\n\n\n\n\n\n\n\n\n\n\nAnswer: 5-D\n\n\n\nHere’s one way you could write your while loop to achieve this output:\n\ni <- 0\n\nwhile (i <= 10) {\n  print(i)\n  i <- i + 2\n}\n\n[1] 0\n[1] 2\n[1] 4\n[1] 6\n[1] 8\n[1] 10\n\n\n\n\n\n\n\n\n\n\nAnswer: 5-E\n\n\n\nHere’s one way you could write your for loop to achieve this output:\n\nnumbers <- c(0:12)\n\nfor (number in numbers) {\n  if (number >= 3) {\n    print(number)\n  }\n}\n\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n[1] 11\n[1] 12\n\n\n\n\n\n\n\n\n\n\nAnswer: 6-A\n\n\n\nYou can accomplish this task with the “charToRaw” function.\n\nx <- \"Trevor rocks\"\nraw_data <- charToRaw(x)\nprint(raw_data)\n\n [1] 54 72 65 76 6f 72 20 72 6f 63 6b 73\n\ntypeof(raw_data)\n\n[1] \"raw\"\n\n\n\n\n\n\n\n\n\n\nAnswer: 6-B\n\n\n\nThe following example demonstrates how you can accomplish this task.\n\nspending <- 120\nbudget <- 100\nover_budget <- spending > budget\nprint(over_budget)\n\n[1] TRUE\n\ntypeof(over_budget)\n\n[1] \"logical\"\n\n\n\n\n\n\n\n\n\n\nAnswer: 7-A\n\n\n\nThe following example demonstrates how you can accomplish this task.\n\nanimal <- c(\"cow\", \"cat\", \"pig\")\nsound <- c(\"moo\", \"meow\", \"oink\")\nanimal_sounds <- data.frame(animal = animal, sound = sound)\nprint(animal_sounds)\n\n  animal sound\n1    cow   moo\n2    cat  meow\n3    pig  oink"
  },
  {
    "objectID": "p2-data-acquisition.html",
    "href": "p2-data-acquisition.html",
    "title": "Part II: Data Acquisition",
    "section": "",
    "text": "Before conducting an analysis you must first acquire your data, e.g. via manual creation, importing pre-constructed data, or leveraging APIs.\n\nIncluded Datasets- R comes with a variety of built-in datasets. This chapter will teach you how to view the catalog of included datasets, preview individual datasets, and begin working with the data.\nImport from Spreadsheets- Most R users will have to work with spreadsheets at some point in their careers. This chapter will teach you how to import data from spreadsheets, e.g. from a .csv or .xlsx file, and get the imported data into a format that’s easy to work with.\nWorking with APIs- API stands for Application Programming Interface. These sorts of tools are commonly used to programmatically pull data from a third party resource. This chapter demonstrates how you can begin to leverage these tools in your own workflows."
  },
  {
    "objectID": "p2c1-included-datasets.html#view-catalog",
    "href": "p2c1-included-datasets.html#view-catalog",
    "title": "8  Included Datasets",
    "section": "8.1 View Catalog",
    "text": "8.1 View Catalog\nYou can view the complete list of datasets available along with a brief description for each one by typing “data()” into your console.\n\ndata()\n\nThis will open a new tab in your RStudio instance that looks similar to the following image:"
  },
  {
    "objectID": "p2c1-included-datasets.html#working-with-included-data",
    "href": "p2c1-included-datasets.html#working-with-included-data",
    "title": "8  Included Datasets",
    "section": "8.2 Working with Included Data",
    "text": "8.2 Working with Included Data\nThe first step to begin working with your chosen dataset is to load it into your environment by using the “data” function with the quoted name of your dataset inside the parentheses. In the following example, we’ll attach the “iris” dataset to our environment.\n\n\n\n\n\n\nNote\n\n\n\nIt may not be necessary for you to load your dataset via the “data” function prior to using it. Additionally, some datasets may require you to add them to your search path by using using the “attach” function (conversely, you can remove datasets from your search path by using the “detach” function).\n\n\n\ndata(\"iris\")\n\nThis command will add a new object “iris” to our R session. Let’s preview the “iris” dataset by using the “head” function.\n\nhead(iris)\n\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\nFinally, you can view more information about any given dataset by typing its name into the “Help” tab in the “Files” pane."
  },
  {
    "objectID": "p2c1-included-datasets.html#common-datasets",
    "href": "p2c1-included-datasets.html#common-datasets",
    "title": "8  Included Datasets",
    "section": "8.3 Common Datasets",
    "text": "8.3 Common Datasets\nHere are a few other datasets commonly used in the R community to practice and to teach.\n\n8.3.1 mtcars\n\nhead(mtcars)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\n8.3.2 faithful\n\nhead(faithful)\n\n\n\n\n\n\neruptions\nwaiting\n\n\n\n\n3.600\n79\n\n\n1.800\n54\n\n\n3.333\n74\n\n\n2.283\n62\n\n\n4.533\n85\n\n\n2.883\n55\n\n\n\n\n\n\n\n8.3.3 ChickWeight\n\nhead(ChickWeight)\n\n\n\n\n\n\nweight\nTime\nChick\nDiet\n\n\n\n\n42\n0\n1\n1\n\n\n51\n2\n1\n1\n\n\n59\n4\n1\n1\n\n\n64\n6\n1\n1\n\n\n76\n8\n1\n1\n\n\n93\n10\n1\n1\n\n\n\n\n\n\n\n8.3.4 Titanic\n\nhead(Titanic)\n\n, , Age = Child, Survived = No\n\n      Sex\nClass  Male Female\n  1st     0      0\n  2nd     0      0\n  3rd    35     17\n  Crew    0      0\n\n, , Age = Adult, Survived = No\n\n      Sex\nClass  Male Female\n  1st   118      4\n  2nd   154     13\n  3rd   387     89\n  Crew  670      3\n\n, , Age = Child, Survived = Yes\n\n      Sex\nClass  Male Female\n  1st     5      1\n  2nd    11     13\n  3rd    13     14\n  Crew    0      0\n\n, , Age = Adult, Survived = Yes\n\n      Sex\nClass  Male Female\n  1st    57    140\n  2nd    14     80\n  3rd    75     76\n  Crew  192     20"
  },
  {
    "objectID": "p2c1-included-datasets.html#resources",
    "href": "p2c1-included-datasets.html#resources",
    "title": "8  Included Datasets",
    "section": "8.4 Resources",
    "text": "8.4 Resources\n\nList of datasets available in Base R: https://www.rdocumentation.org/packages/datasets/versions/3.6.2"
  },
  {
    "objectID": "p2c2-import-from-spreadsheets.html#import-from-.csv-files",
    "href": "p2c2-import-from-spreadsheets.html#import-from-.csv-files",
    "title": "9  Import from Spreadsheets",
    "section": "9.1 Import from .csv Files",
    "text": "9.1 Import from .csv Files\nR has a function called “read.csv” which allows you to read a csv file directly into a dataframe. The following code snippet is a simple example of how to execute this function.\n\n\n\n\n\n\nNote\n\n\n\nIt’s worth noting that it isn’t necessary to store the file path as a variable before calling the function; however, this habit may save you time down the road.\n\n\n\ninput <- \"C:/File Location/example.csv\"\ndf <- read.csv(input)\n\nAlternatively, if you have multiple files from the same directory that need to be imported, you could do something more like the following code snippet.\n\ndirectory <- \"C:/File Location/\"\nfirst_file <- paste(directory, \"first_file.csv\", sep=\"\")\nsecond_file <- paste(directory, \"second_file.csv\", sep=\"\")\nfirst_df <- read.csv(first_file)\nsecond_df <- read.csv(second_file)"
  },
  {
    "objectID": "p2c2-import-from-spreadsheets.html#import-from-.xlsx-files",
    "href": "p2c2-import-from-spreadsheets.html#import-from-.xlsx-files",
    "title": "9  Import from Spreadsheets",
    "section": "9.2 Import from .xlsx Files",
    "text": "9.2 Import from .xlsx Files\nExcel files are handled very similarly to CSV files with the exception being that you will need to use the “read_excel” function from the “readxl” library. The following code snippet demonstrates how to import an Excel file into R.\n\nlibrary(readxl)\ninput <- \"C:/File Location/example.xlsx\"\ndf <- read_excel(input)"
  },
  {
    "objectID": "p2c2-import-from-spreadsheets.html#import-and-combine-multiple-files",
    "href": "p2c2-import-from-spreadsheets.html#import-and-combine-multiple-files",
    "title": "9  Import from Spreadsheets",
    "section": "9.3 Import and Combine Multiple Files",
    "text": "9.3 Import and Combine Multiple Files\nYou may come across a situation where you have multiple CSV files in a folder that need to be combined into a single data frame. The read_csv() function from the readr package accepts the paths to multiple files and will automatically concatenate them along their rows (if the columns match).\n\ninstall.packages(\"readr\")\nlibrary(readr)\n\nYou can list the paths to all .csv files in a directory with the dir() command:\n\nwd <- \"C:/YOURWORKINGDIRECTORY\"\ndir(wd, full.names = TRUE, pattern = \".csv\")\n\nAnd read them into a single data.frame with a single command:\n\ndf <- read_csv(dir(wd, full.names = TRUE, pattern = \".csv\"))\n\n\n\n\n\n\n\nNote\n\n\n\nAll of the headers must match in your CSV files must match exactly for this function to work as expected."
  },
  {
    "objectID": "p2c2-import-from-spreadsheets.html#resources",
    "href": "p2c2-import-from-spreadsheets.html#resources",
    "title": "9  Import from Spreadsheets",
    "section": "9.4 Resources",
    "text": "9.4 Resources\n\ntrevoR package documentation: https://github.com/TrevorFrench/trevoR"
  },
  {
    "objectID": "p2c3-working-with-apis.html#install-packages",
    "href": "p2c3-working-with-apis.html#install-packages",
    "title": "10  Working with APIs",
    "section": "10.1 Install Packages",
    "text": "10.1 Install Packages\n\ninstall.packages(c('httr', 'jsonlite'))"
  },
  {
    "objectID": "p2c3-working-with-apis.html#load-packages-from-the-library",
    "href": "p2c3-working-with-apis.html#load-packages-from-the-library",
    "title": "10  Working with APIs",
    "section": "10.2 Load packages from the library",
    "text": "10.2 Load packages from the library\n\nlibrary('httr')\nlibrary('jsonlite')"
  },
  {
    "objectID": "p2c3-working-with-apis.html#make-request",
    "href": "p2c3-working-with-apis.html#make-request",
    "title": "10  Working with APIs",
    "section": "10.3 Make Request",
    "text": "10.3 Make Request\nPass a URL into the ‘GET’ function and store the response in a variable called ‘res’.\n\nres = GET(\"https://api.helium.io/v1/stats\")\nprint(res)\n\n\nResponse [https://api.helium.io/v1/stats]\n  Date: 2022-08-04 01:25\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 922 B"
  },
  {
    "objectID": "p2c3-working-with-apis.html#parse-explore-data",
    "href": "p2c3-working-with-apis.html#parse-explore-data",
    "title": "10  Working with APIs",
    "section": "10.4 Parse & Explore Data",
    "text": "10.4 Parse & Explore Data\nUse the ‘fromJSON’ function from the ‘jsonlite’ package to parse the response data and then print out the names in the resulting data set.\n\ndata = fromJSON(rawToChar(res$content))\n\nnames(data)\n\n\n[1] \"data\"\n\nGo one level deeper into the data set and print out the names again.\n\ndata = data$data\n\nnames(data)\n\n\n[1] \"token_supply\"     \"election_times\"   \"counts\"           \"challenge_counts\" \"block_times\"\n\nAlternatively, you can loop through the names as follows.\n\nfor (name in names(data)){print(name)}\n\n\n[1] \"token_supply\"\n[1] \"election_times\"\n[1] \"counts\"\n[1] \"challenge_counts\"\n[1] \"block_times\"\n\nGet the ‘token_supply’ field from the data.\n\ntoken_supply = data$token_supply\n\nprint(token_supply)\n\n\n[1] 124675821"
  },
  {
    "objectID": "p2c3-working-with-apis.html#adding-parameters-to-requests",
    "href": "p2c3-working-with-apis.html#adding-parameters-to-requests",
    "title": "10  Working with APIs",
    "section": "10.5 Adding Parameters to Requests",
    "text": "10.5 Adding Parameters to Requests\nAdd ‘min_time’ and ‘max_time’ as parameters on a different endpoint and print the resulting ‘fee’ data.\n\nres = GET(\"https://api.helium.io/v1/dc_burns/sum\",\n    query = list(min_time = \"2020-07-27T00:00:00Z\"\n                 , max_time = \"2021-07-27T00:00:00Z\"))\n\ndata = fromJSON(rawToChar(res$content))\nfee = data$data$fee\nprint(fee)\n\n\n[1] 10112755000"
  },
  {
    "objectID": "p2c3-working-with-apis.html#adding-headers-to-requests",
    "href": "p2c3-working-with-apis.html#adding-headers-to-requests",
    "title": "10  Working with APIs",
    "section": "10.6 Adding Headers to Requests",
    "text": "10.6 Adding Headers to Requests\nExecute the same query as above except this time specify headers. This will likely be necessary when working with an API that requires an API Key.\n\nres = GET(\"https://api.helium.io/v1/dc_burns/sum\",\n    query = list(min_time = \"2020-07-27T00:00:00Z\"\n                 , max_time = \"2021-07-27T00:00:00Z\"),\n    add_headers(`Accept`='application/json', `Connection`='keep-live'))\n\ndata = fromJSON(rawToChar(res$content))\nfee = data$data$fee\nprint(fee)\n\n\n[1] 10112755000"
  },
  {
    "objectID": "p2c3-working-with-apis.html#resources",
    "href": "p2c3-working-with-apis.html#resources",
    "title": "10  Working with APIs",
    "section": "10.7 Resources",
    "text": "10.7 Resources\n\nBlog post by Trevor French: https://medium.com/trevor-french/api-calls-in-r-136290ead81d\n\n\n10.7.1 Helpful APIs\n\nMeta Graph API: https://developers.facebook.com/docs/graph-api/\nTwitter API: https://developer.twitter.com/en/docs/twitter-api\nNASA APIs: https://api.nasa.gov/\nEtherscan API: https://etherscan.io/apis\nCovalent API: https://www.covalenthq.com/docs/api/#/0/0/USD/1\nEDGAR APIs from the SEC: https://www.sec.gov/edgar/sec-api-documentation\nWeather API: https://openweathermap.org/api\nHelium API: https://docs.helium.com/api/"
  },
  {
    "objectID": "p2exercises.html#questions",
    "href": "p2exercises.html#questions",
    "title": "Exercises",
    "section": "Questions",
    "text": "Questions\n\n\n\n\n\n\nExercise: 8-A\n\n\n\nCreate a data frame called “cars” that contains the first five rows of the mtcars dataset by using the “head” function. After printing to the console, you should get the following result:\n#                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n# Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n# Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n# Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n# Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n# Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n\n\n\n\n\n\n\nExercise: 9-A\n\n\n\nWrite a function named “read_file” which will accept a file name as a parameter named “file_name”. The function should then read in a csv with the specified name, store it as a data frame named “df”, and return “df” as the final output.\n\n\n\n\n\n\n\n\nExercise: 9-B\n\n\n\nIn exercise 9-A you created a function that will allow you to read a csv file. Extend this function by adding a second parameter named “csv” which will accept either “TRUE” or “FALSE”. The functionality shouldn’t change if the parameter is equal to “TRUE”; however, if the function is equal to “FALSE”, the function should allow the user to read in an xlsx file instead.\nFor example, if a user wanted to read in a csv file they would use the function in this way:\nread_file(\"iris.csv\", TRUE)\nIf the user wanted to read in an xlsx file they would use the function in this way:\nread_file(\"iris.xlsx\", FALSE)"
  },
  {
    "objectID": "p2exercises.html#answers",
    "href": "p2exercises.html#answers",
    "title": "Exercises",
    "section": "Answers",
    "text": "Answers\n\n\n\n\n\n\nAnswer: 8-A\n\n\n\nThis task can be accomplished with the following code:\n\ncars <- head(mtcars, 5)\nprint(cars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n\n\n\n\n\n\n\n\n\nAnswer: 9-A\n\n\n\nThis task can be accomplished with the following code:\nread_file <- function(file_name) {\n    df <- read.csv(file_name)\n    return(df)\n}\n\n\n\n\n\n\n\n\nAnswer: 9-B\n\n\n\nHere’s one way you could write your function to accomplish this task:\nlibrary(readxl)\n\nread_file <- function(file_name, csv) {\n    if (csv == TRUE) {\n        df <- read.csv(file_name)\n        return(df)\n    }\n\n    if (csv == FALSE) {\n        df <- read_excel(file_name)\n        return(df)\n    }\n}"
  },
  {
    "objectID": "p3-data-preparation.html",
    "href": "p3-data-preparation.html",
    "title": "Part III: Data Preparation",
    "section": "",
    "text": "Most data will not be received in the precise format you need to begin your analysis. The process of data preparation is where you will structure and add features to your data.\n\nData Cleaning- This chapter will cover the basics of cleaning your data, including renaming variables, splitting text, replacing values, dropping columns, and dropping rows. These basic actions will be essential to preparing your data prior to developing insights.\nHandling Missing Data- You may encounter situations where some of your data are missing. This chapter will cover best practices on dealing with missing data and introduce the tools to do so.\nOutliers- Outliers are observations that fall outside the expected scope of the dataset. It’s important to identify outliers and either choose analyses strategies that are robust to their presence or deal with them appropriately before moving into the next analysis phase.\nOrganizing Data- This chapter will focus on sorting, filtering, and grouping your datasets."
  },
  {
    "objectID": "p3c1-data-cleaning.html#renaming-variables",
    "href": "p3c1-data-cleaning.html#renaming-variables",
    "title": "11  Data Cleaning",
    "section": "11.1 Renaming Variables",
    "text": "11.1 Renaming Variables\nLet’s begin by creating a dataset we can use to work through some examples. In our case, we’ll take the first few rows from the “iris” dataset and create a new dataframe called “df”.\n\ndf <- head(iris)\nprint(df)\n\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\nNow, let’s change our column names (which contain different properties of iris species) into “snake case”, e.g. all words are lowercase and separated by underscores. We’ll do this through the use of the “colnames” function. In the following example, we are renaming each column individually by specifying what number column to adjust.\n\ncolnames(df)[1] <- \"sepal_length\"\ncolnames(df)[2] <- \"sepal_width\"\ncolnames(df)[3] <- \"petal_length\"\ncolnames(df)[4] <- \"petal_width\"\ncolnames(df)[5] <- \"species\"\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\nLet’s change the column names again, but use “camel case” this time, e.g. the first word will be lowercase, and all subsequent words will have the first letter capitalized. Instead of using the column number though, this time we’ll use the actual name of the column we want to adjust.\n\ncolnames(df)[colnames(df) == \"sepal_length\"] <- \"sepalLength\"\ncolnames(df)[colnames(df) == \"sepal_width\"] <- \"sepalWidth\"\ncolnames(df)[colnames(df) == \"petal_length\"] <- \"petalLength\"\ncolnames(df)[colnames(df) == \"petal_width\"] <- \"petalWidth\"\n\n\n\n\n\n\nsepalLength\nsepalWidth\npetalLength\npetalWidth\nspecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\nAlternatively, you can use the “rename” function from the “dplyr” package.\n\nlibrary(dplyr)\ndf <- rename(df, \"plantSpecies\" = \"species\")\n\n\n\n\n\n\nsepalLength\nsepalWidth\npetalLength\npetalWidth\nplantSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa"
  },
  {
    "objectID": "p3c1-data-cleaning.html#splitting-text",
    "href": "p3c1-data-cleaning.html#splitting-text",
    "title": "11  Data Cleaning",
    "section": "11.2 Splitting Text",
    "text": "11.2 Splitting Text\nIf you’ve worked in a spreadsheet application before, you’re likely familiar with the “text-to-columns” tool. This tool allows you to split one column of data into multiple columns based on a delimiter. This same functionality is also achievable in R through functions such as the “separate” function from the “tidyr” library.\nTo test this function out, let’s first attach the “tidyr” package and then create a test data frame for us to use.\n\nlibrary(tidyr)\ndf <- data.frame(person = c(\"John_Doe\", \"Jane_Doe\"))\n\n\n\n\n\n\nperson\n\n\n\n\nJohn_Doe\n\n\nJane_Doe\n\n\n\n\n\nWe now have a data frame with one column that contains a first name and a last name combined by an underscore. Let’s now split the two names into their own separate columns.\n\ndf <- df %>% separate(person, c(\"first_name\", \"last_name\"), \"_\")\n\n\n\n\n\n\nfirst_name\nlast_name\n\n\n\n\nJohn\nDoe\n\n\nJane\nDoe\n\n\n\n\n\nLet’s break down what just happened. We first declared that “df” was going to be equal to the output of the function that followed by typing “df <-”. Next we told the separate function that it would be altering the existing dataframe called “df” by typing “df %>%”.\nWe then gave the separate function three arguments. The first argument was the column we were going to be editing, “person”. The second argument was the names of our two new columns, “first_name” and “last_name”. Finally, the third argument was our desired delimiter, “_“."
  },
  {
    "objectID": "p3c1-data-cleaning.html#replace-values",
    "href": "p3c1-data-cleaning.html#replace-values",
    "title": "11  Data Cleaning",
    "section": "11.3 Replace Values",
    "text": "11.3 Replace Values\nWe’ll next go over how you can replace specific values in a dataset. Let’s begin by creating a dataset to work with. The following example will create a dataframe which contains student names and their respective grades on a test.\n\nstudents <- c(\"John\", \"Jane\", \"Joe\", \"Janet\")\ngrades <- c(83, 97, 74, 27)\ndf <- data.frame(student = students, grade = grades)\n\n\n\n\n\n\nstudent\ngrade\n\n\n\n\nJohn\n83\n\n\nJane\n97\n\n\nJoe\n74\n\n\nJanet\n27\n\n\n\n\n\nNow that our dataset is assembled, let’s decide that we’re going to institute a minimum grade of 60. To do this we’re going to need to replace any grade lower than 60 with 60. The following example demonstrates one way you could accomplish that.\n\ndf[which(df$\"grade\" < 60), \"grade\"] <- 60\n\n\n\n\n\n\nstudent\ngrade\n\n\n\n\nJohn\n83\n\n\nJane\n97\n\n\nJoe\n74\n\n\nJanet\n60"
  },
  {
    "objectID": "p3c1-data-cleaning.html#drop-columns",
    "href": "p3c1-data-cleaning.html#drop-columns",
    "title": "11  Data Cleaning",
    "section": "11.4 Drop Columns",
    "text": "11.4 Drop Columns\nLet’s use the “mtcars” dataset to demonstrate how to drop columns\n\ndf <- head(mtcars)\nprint(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\nNext, we can either drop columns by specifying the columns we want to keep or by specifying the ones we want to drop. The following example will get rid of the “carb” column by specifying that we want to keep every other column.\n\ndf <- subset(df, select = c(mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n\n\n\n\n\nAlternatively, let’s try getting rid of the “gear” column directly. We can do this by putting a “-” in front of the “c” function.\n\ndf <- subset(df, select = -c(gear))\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n\n\n\n\n\nOne other way you could drop columns if you wanted to use index numbers rather than column names is demonstrated below.\n\ndf <- df[,-c(1,3:7)]\n\n\n\n\n\n\n\ncyl\nvs\nam\n\n\n\n\nMazda RX4\n6\n0\n1\n\n\nMazda RX4 Wag\n6\n0\n1\n\n\nDatsun 710\n4\n1\n1\n\n\nHornet 4 Drive\n6\n1\n0\n\n\nHornet Sportabout\n8\n0\n0\n\n\nValiant\n6\n1\n0\n\n\n\n\n\nAs you can see, we used the square brackets to select a subset of our dataframe and then pasted our values after the comma to declare that we were choosing columns rather than rows. After that we used the “-” symbol to say that we were choosing columns to drop rather than columns to keep. Finally, we chose to drop columns 1 as well as columns 3 through 7."
  },
  {
    "objectID": "p3c1-data-cleaning.html#drop-rows",
    "href": "p3c1-data-cleaning.html#drop-rows",
    "title": "11  Data Cleaning",
    "section": "11.5 Drop Rows",
    "text": "11.5 Drop Rows\nWe are also able to drop rows with the same method we just used to drop columns with the difference being that we would place our values in front of the comma rather than after the comma. For example, if we wanted to drop the first two rows (otherwise known as observations) from our previous dataframe, we could do the following.\n\ndf <- df[-c(1:2),]\n\n\n\n\n\n\n\ncyl\nvs\nam\n\n\n\n\nDatsun 710\n4\n1\n1\n\n\nHornet 4 Drive\n6\n1\n0\n\n\nHornet Sportabout\n8\n0\n0\n\n\nValiant\n6\n1\n0"
  },
  {
    "objectID": "p3c1-data-cleaning.html#resources",
    "href": "p3c1-data-cleaning.html#resources",
    "title": "11  Data Cleaning",
    "section": "11.6 Resources",
    "text": "11.6 Resources\n\n“Separate” function documentation: https://tidyr.tidyverse.org/reference/separate.html"
  },
  {
    "objectID": "p3c2-handling-missing-data.html#handling-nablank-values",
    "href": "p3c2-handling-missing-data.html#handling-nablank-values",
    "title": "12  Handling Missing Data",
    "section": "12.1 Handling NA/Blank Values",
    "text": "12.1 Handling NA/Blank Values\nThis section will cover common methods and formulas for identifying and isolating missing data. Let’s start by creating a a vector with one “” value and a vector with one “NA” value.\n\nblanks <- c(\"John\", \"Jane\", \"\")\nnas <- c(NA, \"Jane\", \"Joe\")\n\n\nprint(blanks)\n\n[1] \"John\" \"Jane\" \"\"    \n\nprint(nas)\n\n[1] NA     \"Jane\" \"Joe\" \n\n\nWe can use the “is.na” function to identify data with “NA” values. The following example demonstrates how the function works. The output ends up being a “TRUE” or “FALSE” to designate whether each observation is an “NA” value.\n\nis.na(nas)\n\n[1]  TRUE FALSE FALSE\n\n\nWe can then take this one step further and use the function to filter for “NA” values.\n\nonly_nas <- nas[is.na(nas)]\nprint(only_nas)\n\n[1] NA\n\n\nThis works great; however, it’s more likely that you would want to see the values which aren’t equal to “NA”. This can be accomplished by using the “NOT” operator “!”.\n\nno_nas <- nas[!is.na(nas)]\nprint(no_nas)\n\n[1] \"Jane\" \"Joe\" \n\n\nIf your missing data is just an empty string (““) rather than an”NA” value, you can use simple comparison operators to accomplish the same thing.\n\nblanks == \"\"\n\n[1] FALSE FALSE  TRUE\n\nonly_blanks <- blanks[blanks == \"\"]\nprint(only_blanks)\n\n[1] \"\"\n\nno_blanks <- blanks[blanks != \"\"]\nprint(no_blanks)\n\n[1] \"John\" \"Jane\"\n\n\nWhen working with dataframes rather than just vectors, you can also use the “na.omit” function to remove complete rows with “NA” values.\n\nstudents <- c(\"John\", \"Jane\", \"Joe\")\nscores <- c(100, 80, NA)\ndf <- data.frame(student = students, score = scores)\nprint(df)\n\n  student score\n1    John   100\n2    Jane    80\n3     Joe    NA\n\ndf <- na.omit(df)\nprint(df)\n\n  student score\n1    John   100\n2    Jane    80"
  },
  {
    "objectID": "p3c2-handling-missing-data.html#constant-value-imputation",
    "href": "p3c2-handling-missing-data.html#constant-value-imputation",
    "title": "12  Handling Missing Data",
    "section": "12.2 Constant Value Imputation",
    "text": "12.2 Constant Value Imputation\nMany datasets you encounter will likely be missing data. The temptation may be to immediately disregard these observations; however, it’s important to consider what missing data represents in the context of your dataset as well as the context of what your analysis is hoping to achieve. For example, say you are a teacher and you are trying to determine the average test scores of your students. You have a dataset which lists your students names along with their respective test scores. However, you find that one of your students has an “NA” value in place of a test score.\n\nstudents <- c(\"John\", \"Jane\", \"Joe\")\nscores <- c(100, 80, NA)\ndf <- data.frame(student = students, score = scores)\n\nprint(df)\n\n  student score\n1    John   100\n2    Jane    80\n3     Joe    NA\n\n\nDepending on the context, it may make sense for you to ignore this observation prior to calculating the average score. It could also make sense for you to assign a value of “0” to this student’s test score.\nLet’s demonstrate how you would replace “NA” values with a constant value of “0”.\n\ndf[is.na(df)] <- 0\nprint(df)\n\n  student score\n1    John   100\n2    Jane    80\n3     Joe     0"
  },
  {
    "objectID": "p3c2-handling-missing-data.html#central-tendency-imputation",
    "href": "p3c2-handling-missing-data.html#central-tendency-imputation",
    "title": "12  Handling Missing Data",
    "section": "12.3 Central Tendency Imputation",
    "text": "12.3 Central Tendency Imputation\nTwo of the most common measures of central tendency are “mean” and “median”. Suppose you have a dataset that tracks the time employees spend performing a certain task. After review, you realize that several employees have not historically tracked their time. Instead of just ignoring these entries, you decide to try imputing these values.\n\nemployees <- c(\"John\", \"Jane\", \"Joe\", \"Janet\")\nhours_spent <- c(12, 14, NA, 9)\ndf <- data.frame(employee = employees, hours_spent = hours_spent)\n\nprint(df)\n\n  employee hours_spent\n1     John          12\n2     Jane          14\n3      Joe          NA\n4    Janet           9\n\n\nThe following example demonstrates how you can replace missing values with an average of the rest of the employees’ time spent.\n\nmean_value <- mean(df$hours_spent[!is.na(df$hours_spent)])\nprint(mean_value)\n\n[1] 11.66667\n\ndf$hours_spent[is.na(df$hours_spent)] <- mean_value\nprint(df)\n\n  employee hours_spent\n1     John    12.00000\n2     Jane    14.00000\n3      Joe    11.66667\n4    Janet     9.00000\n\n\nAlternatively, we can reset our dataframe and replace “NA” values with the median value by doing the following.\n\n# RESET DATAFRAME\ndf$hours_spent <- hours_spent\n\n# SET MISSING VALUES TO MEDIAN\nmedian_value <- median(df$hours_spent[!is.na(df$hours_spent)])\nprint(median_value)\n\n[1] 12\n\ndf$hours_spent[is.na(df$hours_spent)] <- median_value\nprint(df)\n\n  employee hours_spent\n1     John          12\n2     Jane          14\n3      Joe          12\n4    Janet           9"
  },
  {
    "objectID": "p3c2-handling-missing-data.html#multiple-imputation",
    "href": "p3c2-handling-missing-data.html#multiple-imputation",
    "title": "12  Handling Missing Data",
    "section": "12.4 Multiple Imputation",
    "text": "12.4 Multiple Imputation\nThe two previous examples are types of “single value imputation” as both examples took one value and applied it to every missing value in the dataset. At a very basic level, multiple imputation requires users to come up with some sort of model to fill in missing values. In the following example we are going to demonstrate how you might use a simple linear regression model to perform multiple imputation.\n\n\n\n\n\n\nNote\n\n\n\nLinear regression is covered more in-depth later in this book. Don’t worry if this example feels completely unfamiliar at this point.\n\n\nWe’ll begin by creating a dataframe with both an “x” and a “y” variable.\n\ny <- c(10, 8, NA, 9, 4, NA)\nx <- c(8, 6, 9, 7, 2, 12)\ndf <- data.frame(y = y, x = x)\n\nprint(df)\n\n   y  x\n1 10  8\n2  8  6\n3 NA  9\n4  9  7\n5  4  2\n6 NA 12\n\n\nNext, let’s use the “lm” function to create a linear model and then print out a summary of that model.\n\nmodel <- lm(y ~ x)\nsummary(model)\n\nWarning in summary.lm(model): essentially perfect fit: summary may be unreliable\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n1 2 4 5 \n0 0 0 0 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        2          0     Inf   <2e-16 ***\nx                  1          0     Inf   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0 on 2 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic:   Inf on 1 and 2 DF,  p-value: < 2.2e-16\n\n\nFrom the model summary, we can see that we have a model with a high level of statistical significance. Let’s now use the model coefficients to impute our missing values.\n\nimputed <- predict(model, newdata = list(x = df$x[is.na(df$y)]))\ndf$y[is.na(df$y)] <- imputed\nprint(df)\n\n   y  x\n1 10  8\n2  8  6\n3 11  9\n4  9  7\n5  4  2\n6 14 12"
  },
  {
    "objectID": "p3c2-handling-missing-data.html#resources",
    "href": "p3c2-handling-missing-data.html#resources",
    "title": "12  Handling Missing Data",
    "section": "12.5 Resources",
    "text": "12.5 Resources\n\n“Missing-data Imputation” from Columbia: http://www.stat.columbia.edu/~gelman/arm/missing.pdf"
  },
  {
    "objectID": "p3c3-outliers.html#finding-outliers-visually",
    "href": "p3c3-outliers.html#finding-outliers-visually",
    "title": "13  Outliers",
    "section": "13.1 Finding Outliers Visually",
    "text": "13.1 Finding Outliers Visually\nOne common first step many people employ when looking for outliers is visualizing their datasets so that extreme values can quickly be spotted This section will briefly cover several common visualizations used to identify outliers; however, each of these plots will be explored more in-depth later in the book.\n\n13.1.1 Scatter Plot\nThis is probably the first plot you’ll reach for when trying to visualize outliers in your data. The scatter plot is a great tool to quickly visualize your data at a high level and see if anything major stands out.\n\nplot(mtcars$mpg)\n\n\n\n\nHere’s how a scatter plot with an extreme outlier might look.\n\ndata <- c(1,4,7,9,2,6,3,99,4,2,7,8)\nplot(data)\n\n\n\n\n\n\n13.1.2 Box Plot\nAnother way to quickly visualize outliers is to use the “boxplot” function. This plot will allow you to evaluate outliers in a more systematic way.\n\nboxplot(mtcars$mpg)\n\n\n\n\nThe solid black line represents the median value of your dataset. The top and bottom “whiskers” represent your extreme values (minimum and maximum). The top and bottom of the “box” represent the first and third quartile.\nHere’s an example of a box plot with an extreme outlier.\n\nboxplot(data)\n\n\n\n\n\n\n13.1.3 Histogram\nHistograms will allow you to see how often values occur within certain buckets.\n\nhist(mtcars$mpg)\n\n\n\n\nHere’s a histogram with data that contains an outlier.\n\nhist(data)\n\n\n\n\n\n\n13.1.4 Density Plot\nDensity plots can be thought of as a smoothed version of a histogram. (You can tune the degree of smoothing, e.g. via the adjust argument to the density() function.)\n\nplot(density(mtcars$mpg))\n\n\n\n\nHere’s an example of a density plot with data that contains an outlier.\n\nplot(density(data))"
  },
  {
    "objectID": "p3c3-outliers.html#finding-outliers-statistically",
    "href": "p3c3-outliers.html#finding-outliers-statistically",
    "title": "13  Outliers",
    "section": "13.2 Finding Outliers Statistically",
    "text": "13.2 Finding Outliers Statistically\nWhile examining your data visually may be a convenient and sufficient way to detect outliers in your data, sometimes you may require a more rigorous approach to outlier detection.\n\n13.2.1 Standard Deviation\nOne simple way to check the extremity of your observation is to calculate how many standard deviations it falls from the mean.\nLet’s start by calculating the standard deviation of our dataset by using the “sd” function.\n\nsd <- sd(data)\nprint(sd)\n\n[1] 27.31078\n\n\nNext, let’s calculate the mean of our dataset.\n\nmean <- mean(data)\nprint(mean)\n\n[1] 12.66667\n\n\nFinally, for each record in our vector, let’s calculate how many standard deviations it falls from the mean.\n\nextremity <- abs(data - mean) / sd\nprint(extremity)\n\n [1] 0.4271817 0.3173350 0.2074883 0.1342571 0.3905661 0.2441038 0.3539506\n [8] 3.1611447 0.3173350 0.3905661 0.2074883 0.1708727"
  },
  {
    "objectID": "p3c3-outliers.html#removing-outliers",
    "href": "p3c3-outliers.html#removing-outliers",
    "title": "13  Outliers",
    "section": "13.3 Removing Outliers",
    "text": "13.3 Removing Outliers\nAfter identifying your outliers you have several options to remove them.\nYour first option would be to manually remove a specific outlier.\n\nmanually_cleaned <- data[data != 99]\nprint(manually_cleaned)\n\n [1] 1 4 7 9 2 6 3 4 2 7 8\n\n\nA more robust option would be to rely on your previously performed calculations to remove any observations which are located too far away from the mean.\n\nstatistically_cleaned <- data[extremity < 3]\nprint(statistically_cleaned)\n\n [1] 1 4 7 9 2 6 3 4 2 7 8"
  },
  {
    "objectID": "p3c3-outliers.html#resources",
    "href": "p3c3-outliers.html#resources",
    "title": "13  Outliers",
    "section": "13.4 Resources",
    "text": "13.4 Resources\n“Statistics - Standard Deviation” by W3 Schools: https://www.w3schools.com/statistics/statistics_standard_deviation.php “Identifying outliers with the 1.5xIQR rule”: https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data/box-whisker-plots/a/identifying-outliers-iqr-rule"
  },
  {
    "objectID": "p3c4-organizing-data.html#sort-order-and-rank",
    "href": "p3c4-organizing-data.html#sort-order-and-rank",
    "title": "14  Organizing Data",
    "section": "14.1 Sort, Order, and Rank",
    "text": "14.1 Sort, Order, and Rank\nThree functions you may use to organize your data are “sort”, “order”, and “rank”. The following examples will go through each one and show you how to use them.\nLet’s start by creating a vector to work with.\n\ncompleted_tasks <- c(5, 9, 3, 2, 7)\nprint(completed_tasks)\n\n[1] 5 9 3 2 7\n\n\nNext we’ll sort our data by using the “sort” function. This function will return your original data but sorted in ascending order.\n\nsort(completed_tasks)\n\n[1] 2 3 5 7 9\n\n\nAlternatively, you can set the “decreasing” parameter to “TRUE” to sort your data in descending order.\n\nsort(completed_tasks, decreasing = TRUE)\n\n[1] 9 7 5 3 2\n\n\nThe “order” function will return the index of each item in your vector in sorted order. This function also has a “decreasing” parameter which can be set to “TRUE”.\n\norder(completed_tasks)\n\n[1] 4 3 1 5 2\n\n\nFinally, the “rank” function will return the rank of each item in your vector in ascending order.\n\nrank(completed_tasks)\n\n[1] 3 5 2 1 4"
  },
  {
    "objectID": "p3c4-organizing-data.html#filtering",
    "href": "p3c4-organizing-data.html#filtering",
    "title": "14  Organizing Data",
    "section": "14.2 Filtering",
    "text": "14.2 Filtering\nYou may have noticed in previous chapters that we’ve used comparison operators to filter our data. Let’s review by filtering out completed tasks greater than or equal to 7.\n\ncompleted_tasks[completed_tasks < 7]\n\n[1] 5 3 2\n\n\nAlternatively, you can use the “filter” function from the “dplyr” library. Let’s use this function with the “iris” dataset to filter out any species other than virginica.\n\nhead(iris)\n\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\n\nlibrary(dplyr)\nvirginica <- filter(iris, Species == \"virginica\")\n\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n6.3\n3.3\n6.0\n2.5\nvirginica\n\n\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n7.1\n3.0\n5.9\n2.1\nvirginica\n\n\n6.3\n2.9\n5.6\n1.8\nvirginica\n\n\n6.5\n3.0\n5.8\n2.2\nvirginica\n\n\n7.6\n3.0\n6.6\n2.1\nvirginica"
  },
  {
    "objectID": "p3c4-organizing-data.html#grouping",
    "href": "p3c4-organizing-data.html#grouping",
    "title": "14  Organizing Data",
    "section": "14.3 Grouping",
    "text": "14.3 Grouping\nOne final resource for you to leverage as you organize your data is the “group_by” function from the “dplyr” library.\nIf we wanted to group the iris dataset by species we might do something similar to the following example.\n\nlibrary(dplyr)\ngrouped_species <- iris %>% group_by(Species)\n\nNow if we print out our resulting dataset you’ll notice that the “group_by” operation we just performed doesn’t change how the data looks by itself.\n\nhead(grouped_species)\n\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\nIn order to change the structure of our dataset we’ll need to specify how our groups should be treated by combining the “group_by” function with another dplyr “verb” such as “summarise”.\n\ngrouped_species <- grouped_species %>% summarise(\n    sepal_length = mean(Sepal.Length),\n    sepal_width = mean(Sepal.Width),\n    petal_length = mean(Petal.Length),\n    petal_width = mean(Petal.Width)\n)\n\n\nhead(grouped_species)\n\n\n\n\n\n\nSpecies\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\nsetosa\n5.006\n3.428\n1.462\n0.246\n\n\nversicolor\n5.936\n2.770\n4.260\n1.326\n\n\nvirginica\n6.588\n2.974\n5.552\n2.026\n\n\n\n\n\nNow each of the three species in the iris dataset have their average sepal length, sepal width, petal length, and petal width displayed.\nYou can find more information about the “group_by” function and other dplyr “verbs” in the resources section below."
  },
  {
    "objectID": "p3c4-organizing-data.html#resources",
    "href": "p3c4-organizing-data.html#resources",
    "title": "14  Organizing Data",
    "section": "14.4 Resources",
    "text": "14.4 Resources\n\ndplyr “filter” function documentation: https://dplyr.tidyverse.org/reference/filter.html\ndplyr “group_by” function documentation: https://dplyr.tidyverse.org/reference/group_by.html"
  },
  {
    "objectID": "p3exercises.html#questions",
    "href": "p3exercises.html#questions",
    "title": "Exercises",
    "section": "Questions",
    "text": "Questions\n\n\n\n\n\n\nExercise: 11-A\n\n\n\nCreate a dataframe named “df” which is equal to the first three columns and the first five rows of the “mtcars” dataset. Next, rename the “mpg” column to “miles_per_gallon”.\nAfter printing the resulting dataframe to the console you should have the following results:\n#                   miles_per_gallon cyl disp\n# Mazda RX4                     21.0   6  160\n# Mazda RX4 Wag                 21.0   6  160\n# Datsun 710                    22.8   4  108\n# Hornet 4 Drive                21.4   6  258\n# Hornet Sportabout             18.7   8  360\n\n\n\n\n\n\n\n\nExercise: 12-A\n\n\n\nYou are given the following dataframe:\nvar_1 <- c(3, 4, 2, 9, NA, 2, 7)\nvar_2 <- c(8, NA, 6, 4, 8, 5, 5)\ndf <- data.frame(var_1 = var_1, var_2 = var_2)\nprint(df)\n#   var_1 var_2\n# 1     3     8\n# 2     4    NA\n# 3     2     6\n# 4     9     4\n# 5    NA     8\n# 6     2     5\n# 7     7     5\nCreate a new dataframe called “cleaned_df” which is equal to “df” except with both rows which contain “NA” values removed.\nThe final output of “cleaned_df” should look like this:\n#   var_1 var_2\n# 1     3     8\n# 3     2     6\n# 4     9     4\n# 6     2     5\n# 7     7     5\n\n\n\n\n\n\n\n\nExercise: 12-B\n\n\n\nTake the original “df” dataframe from exercise 12-A and apply a constant value of “5” to each “NA” value. Store this new dataframe in a variable named “constant_value”.\nYour final output after printing “constant_value” to the console should look like this:\nprint(constant_value)\n#   var_1 var_2\n# 1     3     8\n# 2     4     5\n# 3     2     6\n# 4     9     4\n# 5     5     8\n# 6     2     5\n# 7     7     5\n\n\n\n\n\n\n\n\nExercise: 12-C\n\n\n\nTake the same “df” dataframe from exercises 12-A and 12-B and apply an average value of each column to “NA” values in each respective column. Store this new dataframe in a variable named “mean_value”.\nYour final output after printing “mean_value” to the console should look like this:\nprint(mean_value)\n#   var_1 var_2\n# 1   3.0     8\n# 2   4.0     6\n# 3   2.0     6\n# 4   9.0     4\n# 5   4.5     8\n# 6   2.0     5\n# 7   7.0     5\n\n\n\n\n\n\n\n\nExercise: 13-A\n\n\n\nUse the “Nile” dataset to create a histogram to view the distribution of it’s data.\n\n\n\n\n\n\n\n\nExercise: 14-A\n\n\n\nTake the dataframe created in exercise 11-A and drop any row where the “disp” column is equal to “160”.\nYou should receive the following results when you print the resulting dataframe to the console.\n#                   miles_per_gallon cyl disp\n# Datsun 710                    22.8   4  108\n# Hornet 4 Drive                21.4   6  258\n# Hornet Sportabout             18.7   8  360"
  },
  {
    "objectID": "p3exercises.html#answers",
    "href": "p3exercises.html#answers",
    "title": "Exercises",
    "section": "Answers",
    "text": "Answers\n\n\n\n\n\n\nAnswer: 11-A\n\n\n\nThis task could be accomplished in the following way:\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf <- mtcars[1:5, 1:3]\ndf <- rename(df, \"miles_per_gallon\" = \"mpg\")\nprint(df)\n\n                  miles_per_gallon cyl disp\nMazda RX4                     21.0   6  160\nMazda RX4 Wag                 21.0   6  160\nDatsun 710                    22.8   4  108\nHornet 4 Drive                21.4   6  258\nHornet Sportabout             18.7   8  360\n\n\n\n\n\n\n\n\n\n\nAnswer: 12-A\n\n\n\nThis task could be accomplished in the following way:\n\nvar_1 <- c(3, 4, 2, 9, NA, 2, 7)\nvar_2 <- c(8, NA, 6, 4, 8, 5, 5)\ndf <- data.frame(var_1 = var_1, var_2 = var_2)\ncleaned_df <- na.omit(df)\nprint(cleaned_df)\n\n  var_1 var_2\n1     3     8\n3     2     6\n4     9     4\n6     2     5\n7     7     5\n\n\n\n\n\n\n\n\n\n\nAnswer: 12-B\n\n\n\nThere are several ways this task could be accomplished; however, the following example demonstrates one way to do it.\n\nvar_1 <- c(3, 4, 2, 9, NA, 2, 7)\nvar_2 <- c(8, NA, 6, 4, 8, 5, 5)\ndf <- data.frame(var_1 = var_1, var_2 = var_2)\n\nconstant_value <- df\nconstant_value[is.na(constant_value)] <- 5\nprint(constant_value)\n\n  var_1 var_2\n1     3     8\n2     4     5\n3     2     6\n4     9     4\n5     5     8\n6     2     5\n7     7     5\n\n\n\n\n\n\n\n\n\n\nAnswer: 12-C\n\n\n\nThere are several ways this task could be accomplished; however, the following example demonstrates one way to do it.\n\nvar_1 <- c(3, 4, 2, 9, NA, 2, 7)\nvar_2 <- c(8, NA, 6, 4, 8, 5, 5)\ndf <- data.frame(var_1 = var_1, var_2 = var_2)\n\nmean_1 <- mean(df$var_1[!is.na(df$var_1)])\nmean_2 <- mean(df$var_2[!is.na(df$var_2)])\n\nmean_value <- df\nmean_value$var_1[is.na(mean_value$var_1)] <- mean_1\nmean_value$var_2[is.na(mean_value$var_2)] <- mean_2\nprint(mean_value)\n\n  var_1 var_2\n1   3.0     8\n2   4.0     6\n3   2.0     6\n4   9.0     4\n5   4.5     8\n6   2.0     5\n7   7.0     5\n\n\n\n\n\n\n\n\n\n\nAnswer: 13-A\n\n\n\n\nhist(Nile)\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer: 14-A\n\n\n\nThis task could be accomplished in the following way:\n\nlibrary(dplyr)\ndf <- mtcars[1:5, 1:3]\ndf <- rename(df, \"miles_per_gallon\" = \"mpg\")\n\ndf <- filter(df, disp != 160)\nprint(df)\n\n                  miles_per_gallon cyl disp\nDatsun 710                    22.8   4  108\nHornet 4 Drive                21.4   6  258\nHornet Sportabout             18.7   8  360"
  },
  {
    "objectID": "p4-developing-insights.html",
    "href": "p4-developing-insights.html",
    "title": "Part IV: Developing Insights",
    "section": "",
    "text": "“A learning organization is an organization skilled at creating, acquiring, and transferring knowledge, and at modifying its behavior to reflect new knowledge and insights.”  -David A. Garvin (Garvin 1993)\n\nOnce your data is prepared, you can begin to make sense of it and develop insights about its meaning. For many, this is where the data analysis process becomes the most fulfilling. This is the point where you get to reap what you’ve sown in the previous phases of the data analysis lifecycle.\n\nSummary Statistics- Summary statistics are usually where one starts when beginning to develop insights. You may hear the phrase “Exploratory Data Analysis” (sometimes abbreviated “EDA”) throughout your career. This is the point where you try to get a high-level understanding of your data through methods such as summary statistics.\nRegression- Regression is a common statistical technique employed by many to make generalizations as well as predictions about data.\nPlotting- This chapter will cover the basics of creating plots in R. It will begin by demonstrating the plotting capabilities available in R “out of the box”. You will also be given resources to learn more about “ggplot2” which is one of the most common plotting libraries in R.\n\n\n\n\n\nGarvin, David A. 1993. “Building a Learning Organization.” Harvard Business Review July-August 1993."
  },
  {
    "objectID": "p4c1-summary-statistics.html#quantitative-data",
    "href": "p4c1-summary-statistics.html#quantitative-data",
    "title": "15  Summary Statistics",
    "section": "15.1 Quantitative Data",
    "text": "15.1 Quantitative Data\nWhen dealing with continuous data, one of the quickest ways to get a high level view of your data is by using the “summary” function. This function will return your extreme (minimum and maximum) values, your median, mean, 1st quantile, and 3rd quantile.\n\nsummary(mtcars$mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.40   15.43   19.20   20.09   22.80   33.90 \n\n\nAlternatively, you can use the following eight functions to retrieve specific information about your data.\n\n# Returns the average\nmean(mtcars$mpg)\n\n[1] 20.09062\n\n# Returns the median\nmedian(mtcars$mpg)\n\n[1] 19.2\n\n# Returns the standard deviation\nsd(mtcars$mpg)\n\n[1] 6.026948\n\n# Returns the sample variance\nvar(mtcars$mpg)\n\n[1] 36.3241\n\n# Returns the minimum value\nmin(mtcars$mpg)\n\n[1] 10.4\n\n# Returns the maximum value\nmax(mtcars$mpg)\n\n[1] 33.9\n\n# Returns the minimum and maximum value\nrange(mtcars$mpg)\n\n[1] 10.4 33.9\n\n# Returns quantile data\nquantile(mtcars$mpg)\n\n    0%    25%    50%    75%   100% \n10.400 15.425 19.200 22.800 33.900"
  },
  {
    "objectID": "p4c1-summary-statistics.html#qualitative-data",
    "href": "p4c1-summary-statistics.html#qualitative-data",
    "title": "15  Summary Statistics",
    "section": "15.2 Qualitative Data",
    "text": "15.2 Qualitative Data\nIf you’re working with data that is categorical and encoded as a factor, you can view all categories by using the “levels” function.\n\nlevels(iris$Species)\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nHowever, if you want to count the number of occurrences for each level, you can use the “table” function.\n\ntable(iris$Species)\n\n\n    setosa versicolor  virginica \n        50         50         50 \n\n\nIf you need to keep digging for insights, you can represent your categories however you’d like to using the “group_by” function covered in the last chapter."
  },
  {
    "objectID": "p4c1-summary-statistics.html#resources",
    "href": "p4c1-summary-statistics.html#resources",
    "title": "15  Summary Statistics",
    "section": "15.3 Resources",
    "text": "15.3 Resources\n\n“Exploring Data and Descriptive Statistics (using R)” from princeton: https://www.princeton.edu/~otorres/sessions/s2r.pdf"
  },
  {
    "objectID": "p4c2-regression.html#linear-regression",
    "href": "p4c2-regression.html#linear-regression",
    "title": "16  Regression",
    "section": "16.1 Linear Regression",
    "text": "16.1 Linear Regression\nThe first kind of regression we’ll cover is linear regression. Linear regression will use your data to come up with a linear model that describes the general trend of your data. Generally speaking, a linear model will consist of a dependent variable (y), at least one independent variable (x), coefficients to go along with each independent variable, and an intercept. Here’s one common linear model you may remember:\n\\[\ny = mx + b\n\\]\nThis is a simple linear model many people begin with where x and y are the independent and dependent variables, respectively, m is the slope (or coefficient of x), and b is the intercept.\nTo perform linear regression in R, you’ll use the “lm” function. Let’s try it out on the “faithful” dataset.\n\nhead(faithful)\n\n\n\n\n\n\neruptions\nwaiting\n\n\n\n\n3.600\n79\n\n\n1.800\n54\n\n\n3.333\n74\n\n\n2.283\n62\n\n\n4.533\n85\n\n\n2.883\n55\n\n\n\n\n\nThe “lm” function will accept at least two parameters which represent “y” and “x” in this format:\n\nlm(y ~ x)\n\nLet’s try this out by setting the y variable to eruptions and the x variable to waiting. We can then view the output of our linear model by using the “summary” function.\n\nlm <- lm(faithful$eruptions ~ faithful$waiting)\nsummary(lm)\n\n\nCall:\nlm(formula = faithful$eruptions ~ faithful$waiting)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.29917 -0.37689  0.03508  0.34909  1.19329 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      -1.874016   0.160143  -11.70   <2e-16 ***\nfaithful$waiting  0.075628   0.002219   34.09   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4965 on 270 degrees of freedom\nMultiple R-squared:  0.8115,    Adjusted R-squared:  0.8108 \nF-statistic:  1162 on 1 and 270 DF,  p-value: < 2.2e-16\n\n\nThis summary will show us the statistical significance of our model along with all relevant statistics to correctly interpret the significance. Additionally, we now have our model coefficients. From this summary we can assume that our model looks something like this:\n\\[\neruptions = waiting * 0.075628 - 1.874016\n\\]\nLet’s break down everything that the model summary returns.\n\nThe “Call” section calls the model that you created\nThe “Residuals” section gives you a summary of all of your model residuals. Simply put, a residual denotes how far away any given point falls from the predicted value.\nThe “Coefficients” section gives us our model coefficients, our intercept, and statistical values to determine their significance.\n\nFor each coefficient, we are given the respective standard error. The standard error is used to measure the precision of coefficient’s estimate.\nNext, we have a t value for each coefficient. The t value is calculated by dividing the coefficient by the standard error.\nFinally, you have the p value accompanied by symbols to denote the corresponding significance level.\n\nThe residual standard error gives you a way to measure the standard deviation of the residuals and is calculated by dividing residual sum of squares by the residual degrees of freedom and taking the square root of that where the residual degrees of freedom is equal to total observations - total model parameters - 1.\nR-squared gives you the proportion of variance that can be explained by your model. Your adjusted R-squared statistic will tell you the same thing but will adjust for the number of variables you’ve included in your model.\nYour F-statistic will help you to understand the probability that all of your model parameters are actually equal to zero."
  },
  {
    "objectID": "p4c2-regression.html#multiple-regression",
    "href": "p4c2-regression.html#multiple-regression",
    "title": "16  Regression",
    "section": "16.2 Multiple Regression",
    "text": "16.2 Multiple Regression\nIf you had more x variables you wanted to add to your linear model, you could add them just like you would in any other math equation. Here’s an example:\n\nlm(data$y ~ data$x1 + data$x2 + data$x3 + data$x4)\n\nAdditionally, you can use the “data” parameter rather than putting the name of the dataset before every variable.\n\nlm(y ~ x1 + x2 + x3 + x4, data = data)\n\nLet’s try a real example with the mtcars dataset.\n\nhead(mtcars)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\nNow, let’s try to predict mpg and use every other column as a variable then see what the results look like.\n\nlm <- lm(mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb\n            , data = mtcars)\nsummary(lm)\n\n\nCall:\nlm(formula = mpg ~ cyl + disp + hp + drat + wt + qsec + vs + \n    am + gear + carb, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4506 -1.6044 -0.1196  1.2193  4.6271 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept) 12.30337   18.71788   0.657   0.5181  \ncyl         -0.11144    1.04502  -0.107   0.9161  \ndisp         0.01334    0.01786   0.747   0.4635  \nhp          -0.02148    0.02177  -0.987   0.3350  \ndrat         0.78711    1.63537   0.481   0.6353  \nwt          -3.71530    1.89441  -1.961   0.0633 .\nqsec         0.82104    0.73084   1.123   0.2739  \nvs           0.31776    2.10451   0.151   0.8814  \nam           2.52023    2.05665   1.225   0.2340  \ngear         0.65541    1.49326   0.439   0.6652  \ncarb        -0.19942    0.82875  -0.241   0.8122  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.65 on 21 degrees of freedom\nMultiple R-squared:  0.869, Adjusted R-squared:  0.8066 \nF-statistic: 13.93 on 10 and 21 DF,  p-value: 3.793e-07\n\n\nFrom here, you would likely tweak your model further based on the significance statistics we see here; however, that’s outside the scope of what we’re doing in this book. Take a look in the resources section at the end of this chapter to dive deeper into developing regression models."
  },
  {
    "objectID": "p4c2-regression.html#logistic-regression",
    "href": "p4c2-regression.html#logistic-regression",
    "title": "16  Regression",
    "section": "16.3 Logistic Regression",
    "text": "16.3 Logistic Regression\nLogistic regression is commonly used when your dependent variable (y) binomial (0 or 1). Instead of using the “lm” function though, you will use the “glm” function. Let’s try this out on the mtcars dataset again but this time with “am” as the dependent variable.\n\nglm <- glm(am ~ cyl + hp + wt, family = binomial, data = mtcars)\nsummary(glm)\n\n\nCall:\nglm(formula = am ~ cyl + hp + wt, family = binomial, data = mtcars)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-2.17272  -0.14907  -0.01464   0.14116   1.27641  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept) 19.70288    8.11637   2.428   0.0152 *\ncyl          0.48760    1.07162   0.455   0.6491  \nhp           0.03259    0.01886   1.728   0.0840 .\nwt          -9.14947    4.15332  -2.203   0.0276 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43.2297  on 31  degrees of freedom\nResidual deviance:  9.8415  on 28  degrees of freedom\nAIC: 17.841\n\nNumber of Fisher Scoring iterations: 8"
  },
  {
    "objectID": "p4c2-regression.html#resources",
    "href": "p4c2-regression.html#resources",
    "title": "16  Regression",
    "section": "16.4 Resources",
    "text": "16.4 Resources\n\n“Lecture 9 - Linear regression in R” by Professor Alexandra Chouldechova at Carnegie Mellon University: https://www.andrew.cmu.edu/user/achoulde/94842/lectures/lecture09/lecture09-94842.html\n“Logistic Regression” by Erin Bugbee and Jared Wilber: https://mlu-explain.github.io/logistic-regression/\n“Visualizing OLS Linear Regression Assumptions in R” by Trevor French https://medium.com/trevor-french/visualizing-ols-linear-regression-assumptions-in-r-e762ba7afaff"
  },
  {
    "objectID": "p4c3-plotting.html#plotting-your-regression-model",
    "href": "p4c3-plotting.html#plotting-your-regression-model",
    "title": "17  Plotting",
    "section": "17.1 Plotting your Regression Model",
    "text": "17.1 Plotting your Regression Model\nNow that you’ve learned how create a linear regression model, let’s look at how you might go about representing it visually.\nHere’s a preview of the dataset we’ll be using:\n\n\n\n\n\n\n\n\ny\nx\n\n\n\n\n-4.400327\n1\n\n\n5.428396\n2\n\n\n1.401835\n3\n\n\n8.347445\n4\n\n\n4.653595\n5\n\n\n1.768966\n6\n\n\n\n\n\nWe’ll begin by just creating a scatter plot of the raw data.\n\nplot(df$x, df$y)\n\n\n\n\nAdditionally, you can alter the appearance of your points by using the “pch”, “cex”, and “col” options. PCH stands for Plot Character and will adjust the symbol used for your points. The available point shapes are listed in the image below.\n\nggpubr::show_point_shapes()\n\n\n\n\nThe “cex” option allows you to adjust the symbol size. The default value is 1. If you were to change the value to .75, for example, the plot symbol would be scaled down the 3/4 of the default size. The “col” option allows you to adjust the color of your plot symbols.\n\nplot(df$x\n        , df$y\n        , col=rgb(0.4,0.4,0.8,0.6)\n        , pch=16\n        , cex=1.2)\n\n\n\n\nYou can adjust the axes with the “xlab”, “ylab”, “xaxt”, and “yaxt” options (amongst other available options). In the following example we will remove the axes altogether.\n\nplot(df$x\n        , df$y\n        , col=rgb(0.4,0.4,0.8,0.6)\n        , pch=16\n        , cex=1.2\n        , xlab=\"\"\n        , ylab=\"\"\n        , xaxt=\"n\"\n        , yaxt=\"n\")\n\n\n\n\nFinally, you can add a trend line by creating a model and adding the fitted values to the graph. We’ll also adjust the line width and color with the “lwd” and “col” parameters, respectively.\n\nplot(df$x\n        , df$y\n        , col=rgb(0.4,0.4,0.8,0.6)\n        , pch=16\n        , cex=1.2\n        , xlab=\"\"\n        , ylab=\"\"\n        , xaxt=\"n\"\n        , yaxt=\"n\")\n\nmodel <- lm(df$y ~ df$x)\nabline(model, col=2, lwd=2)\n\n\n\n\nThe model also returns confidence intervals for the predictions, which can be added\n\n# Extract the upper and lower 95% confidence intervals of the predictions\nconf_interval <- predict(\n  model, \n  newdata=data.frame(x=df$x), \n  interval = \"prediction\",\n  level = 0.95)\n\nplot(df$x\n        , df$y\n        , col=rgb(0.4,0.4,0.8,0.6)\n        , pch=16\n        , cex=1.2\n        , xlab=\"\"\n        , ylab=\"\"\n        , xaxt=\"n\"\n        , yaxt=\"n\")\nabline(model, col=2, lwd=2)\nlines(df$x, conf_interval[,2], col=\"blue\", lty=2)\nlines(df$x, conf_interval[,3], col=\"blue\", lty=2)"
  },
  {
    "objectID": "p4c3-plotting.html#plots-available-in-base-r",
    "href": "p4c3-plotting.html#plots-available-in-base-r",
    "title": "17  Plotting",
    "section": "17.2 Plots Available in Base R",
    "text": "17.2 Plots Available in Base R\nNow that you’ve seen how to build a scatterplot in R, let’s take a look at other plots available in Base R.\n\n17.2.1 Box Plot\nOne plot you’ve already seen in the outliers chapter is the box plot. These plots can be created via the “boxplot” function.\n\nboxplot(mtcars$mpg)\n\n\n\n\nWe can build on this plot by specifying the dataset with the “data” parameter, removing the “mtcars$” prefix from our variable, adding a plot title with the “main” parameter, and adding axis labels with the “xlab” and “ylab” parameters. Additionally, we are going to add an additional variable for our data to be categorized by.\n\nboxplot(mpg ~ gear\n            , data = mtcars\n            , main = \"Car Mileage by Gear\"\n            , xlab = \"Number of Forward Gears\"\n            , ylab = \"Miles Per Gallon\")\n\n\n\n\nFinally, we can set the box colors with the “col” parameter and set “notch” equal to “TRUE” to give our boxes notches. If the notches of two plots do not overlap this is ‘strong evidence’ that the two medians differ Chambers and Tukey (1983).\n\nboxplot(mpg ~ am\n            , data = mtcars\n            , notch = TRUE\n            , col = (c(\"blue\", \"grey\"))\n            , main = \"Car Mileage by Engine\"\n            , xlab = \"Automatic?\"\n            , ylab = \"Miles Per Gallon\")\n\n\n\n\n\n\n17.2.2 Plot Matrix\nYou can use the “pairs” function to create a plot matrix. Let’s use the iris dataset to demonstrate this.\n\npairs(iris)\n\n\n\n\nThis plot gives us the ability to see how each variable interacts with one another.\n\n\n17.2.3 Pie Chart\nLet’s try plotting a pie chart of species in the iris dataset via the “pie” function. This function accepts numerical values so we’ll need to use the “table” function on our column as well.\n\npie(table(iris$Species))\n\n\n\n\nYou can view the full list of available parameters for this and other functions through the help tab in the files pane in R Studio.\n\n\n\n\n\n\n\n17.2.4 Bar Plot\nLet’s try a bar plot on the same dataset with the “barplot” function.\n\nbarplot(table(iris$Species))\n\n\n\n\n\n\n17.2.5 Histogram\nYou may recall that we also used histigrams in the outliers chapter to try to visually identify extreme values. Here’s a quick recap:\n\nhist(mtcars$mpg)\n\n\n\n\n\n\n17.2.6 Density Plot\nWe also used the following example in the outliers chapter to create a density plot:\n\nplot(density(mtcars$mpg))\n\n\n\n\nWe can take this one step further by adding a title and a shape to the plot.\n\nmpg <- density(mtcars$mpg)\nplot(mpg, main=\"MPG Distribution\")\npolygon(mpg, col=\"lightblue\", border=\"black\")\n\n\n\n\n\n\n17.2.7 Dot Chart\n\nsalesperson <- c(\"Susan\", \"Taylor\", \"Steven\"\n                    , \"Michael\", \"Reagan\", \"Michael\"\n                    , \"Alaka\", \"Trevor\", \"Isaac\"\n                    , \"Jordan\", \"Aaron\", \"Miles\")\nproduct <- c(\"Professional Services\", \"Professional Services\"\n                , \"Professional Services\", \"Professional Services\"\n                , \"Software\",  \"Software\",  \"Software\",  \"Software\"\n                , \"Hardware\", \"Hardware\", \"Hardware\", \"Hardware\")\nsales <- c(10, 7, 13, 18, 12, 19, 14, 16, 21, 9, 17, 19)\ndf <- data.frame(salesperson = salesperson, product = product, sales = sales)\n\ndotchart(df$sales)\n\n\n\ndotchart(df$sales, labels = df$salesperson)\n\n\n\ngroups <- as.factor(df$product)\ndotchart(df$sales, labels = df$salesperson, groups = groups)\n\n\n\ngroup_colors <-  c(\"blue\", \"darkred\", \"darkgreen\")\ndotchart(df$sales\n            , labels = df$salesperson\n            , groups = groups\n            , gcolor = group_colors)\n\n\n\ndotchart(df$sales\n            , labels = df$salesperson\n            , groups = groups\n            , gcolor = group_colors\n            , color = group_colors[groups]\n            , pch = 16)"
  },
  {
    "objectID": "p4c3-plotting.html#resources",
    "href": "p4c3-plotting.html#resources",
    "title": "17  Plotting",
    "section": "17.3 Resources",
    "text": "17.3 Resources\n\nggplot2 documentation: https://ggplot2.tidyverse.org/\nggplot2 cheat sheet: https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\nggplot2 extension gallery: https://exts.ggplot2.tidyverse.org/gallery/\nR colors: http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf\n\n\n\n\n\nChambers, Cleveland, J. M., and P. A. Tukey. 1983. Graphical Methods for Data Analysis. Wadsworth & Brooks/Cole."
  },
  {
    "objectID": "p4exercises.html#questions",
    "href": "p4exercises.html#questions",
    "title": "Exercises",
    "section": "Questions",
    "text": "Questions\n\n\n\n\n\n\nExercise: 15-A\n\n\n\nUse the “summary” function to get summary statistics for all columns in the “mtcars” dataset.\nYour final output should resemble the following:\n#       mpg             cyl             disp             hp       \n#  Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n#  1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n#  Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n#  Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n#  3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n#  Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n#       drat             wt             qsec             vs        \n#  Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n#  1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n#  Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n#  Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n#  3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n#  Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n#        am              gear            carb      \n#  Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n#  1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n#  Median :0.0000   Median :4.000   Median :2.000  \n#  Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n#  3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n#  Max.   :1.0000   Max.   :5.000   Max.   :8.000 \n\n\n\n\n\n\n\n\nExercise: 16-A\n\n\n\nUse the “lm” function to create a linear model using the “ChickWeight” dataset. Your model should predict the “weight” variable using the “Diet” and “Time” variables.\nName your linear model “lm” and then view a summary of your model using the “summary” function. The output of your summary should look like this:\n# Call:\n# lm(formula = weight ~ Diet + Time, data = ChickWeight)\n\n# Residuals:\n#      Min       1Q   Median       3Q      Max \n# -136.851  -17.151   -2.595   15.033  141.816 \n\n# Coefficients:\n#             Estimate Std. Error t value Pr(>|t|)    \n# (Intercept)  10.9244     3.3607   3.251  0.00122 ** \n# Diet2        16.1661     4.0858   3.957 8.56e-05 ***\n# Diet3        36.4994     4.0858   8.933  < 2e-16 ***\n# Diet4        30.2335     4.1075   7.361 6.39e-13 ***\n# Time          8.7505     0.2218  39.451  < 2e-16 ***\n# ---\n# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n# Residual standard error: 35.99 on 573 degrees of freedom\n# Multiple R-squared:  0.7453,  Adjusted R-squared:  0.7435 \n# F-statistic: 419.2 on 4 and 573 DF,  p-value: < 2.2e-16\n\n\n\n\n\n\n\n\nExercise: 17-A\n\n\n\nCreate a density plot using the “Nile” dataset."
  },
  {
    "objectID": "p4exercises.html#answers",
    "href": "p4exercises.html#answers",
    "title": "Exercises",
    "section": "Answers",
    "text": "Answers\n\n\n\n\n\n\nAnswer: 15-A\n\n\n\nHere’s how you can accomplish this task:\n\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\n\n\n\n\n\n\n\n\nAnswer: 16-A\n\n\n\nYou can create your model with the following code:\n\nlm <- lm(weight ~ Diet + Time, data = ChickWeight)\nsummary(lm)\n\n\nCall:\nlm(formula = weight ~ Diet + Time, data = ChickWeight)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-136.851  -17.151   -2.595   15.033  141.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  10.9244     3.3607   3.251  0.00122 ** \nDiet2        16.1661     4.0858   3.957 8.56e-05 ***\nDiet3        36.4994     4.0858   8.933  < 2e-16 ***\nDiet4        30.2335     4.1075   7.361 6.39e-13 ***\nTime          8.7505     0.2218  39.451  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 35.99 on 573 degrees of freedom\nMultiple R-squared:  0.7453,    Adjusted R-squared:  0.7435 \nF-statistic: 419.2 on 4 and 573 DF,  p-value: < 2.2e-16\n\n\n\n\n\n\n\n\n\n\nAnswer: 17-A\n\n\n\nYou can create your density plot with the following code:\n\nplot(density(Nile))"
  },
  {
    "objectID": "p5-reporting.html",
    "href": "p5-reporting.html",
    "title": "Part V: Reporting",
    "section": "",
    "text": "“It feels like we’re all suffering from information overload or data glut. And the good news is there might be an easy solution to that, and that’s using our eyes more. So, visualizing information, so that we can see the patterns and connections that matter and then designing that information so it makes more sense, or it tells a story, or allows us to focus only on the information that’s important. Failing that, visualized information can just look really cool.”  -David McCandless (McCandless 2010)\n\nFinally, it’s important to report on your data to make it easy for others to extract and understand the information that is most relevant.\n\nSpreadsheets- Spreadsheets are a common way to communicate information to stakeholders. This chapter will go over how to export .xlsx and .csv files from R, how to format those spreadsheets, and how to add formulas to them.\nR Markdown- R Markdown allows you to create documents in a programmatic fashion that improves reproducibility. This chapter will cover some of the different formats that are available in R as well as how to create them.\nR Shiny- R Shiny is a tool used to develop web applications and is commonly deployed in the use of creating dashboards, hosting static reports, and custom tooling.\n\n\n\n\n\nMcCandless, David. 2010. “The Beauty of Data Visualization.” https://www.ted.com/talks/david_mccandless_the_beauty_of_data_visualization/transcript?language=en."
  },
  {
    "objectID": "p5c1-spreadsheets.html#export",
    "href": "p5c1-spreadsheets.html#export",
    "title": "18  Spreadsheets",
    "section": "18.1 Export",
    "text": "18.1 Export\n\n18.1.1 Export .csv Files\nIn order to export a dataframe to a CSV file, you can use the “write.csv” function. This function will accept a dataframe followed by the desired output location of your file. Let’s start by creating a sample dataframe to work with.\n\npeople <- c(\"John\", \"Jane\", NA)\nid <- c(12, 27, 23)\ndf <- data.frame(id = id, person = people)\n\n\n\n\n\n\nid\nperson\n\n\n\n\n12\nJohn\n\n\n27\nJane\n\n\n23\nNA\n\n\n\n\n\nNow, let’s specify the location we want to store the CSV file at and execute the “write.csv” function. (We use the file.path() to specify a path to the example.csv file in a temporary directory that will automatically be erased when your R session ends.)\n\noutput <- file.path(tempdir(), \"example.csv\")\nwrite.csv(df, output)\n\nThis will give you a file that looks like the following image.\n\n\n\n\n\nYou’ll notice that the first column contains the row numbers of the dataframe. This can be remedied by setting “row.names” to “FALSE” as follows.\n\nwrite.csv(df, output, row.names = FALSE)\n\nThis will yield the following result.\n\n\n\n\n\nFinally, you’ll notice that one of the names is an “NA” value. You can tell R how to handle these values at the time of exporting your file with the “na” argument. This argument will replace any “NA” values with the value of your choice. Let’s try replacing the “NA” value with “Unspecified”.\n\nwrite.csv(df, output, row.names = FALSE, na = \"Unspecified\")\n\nThis results in the following output:\n\n\n\n\n\n\n\n18.1.2 Export .xlsx Files\nExcel files are handled very similarly to CSV files except that you will need to use the “write_excel” function from the “writexl” package. The following code snippet demonstrates how to export your data to an Excel file.\n\nlibrary(writexl)\noutput <- \"C:/File Location/example.xlsx\"\nwrite_xlsx(df, output)"
  },
  {
    "objectID": "p5c1-spreadsheets.html#formatting",
    "href": "p5c1-spreadsheets.html#formatting",
    "title": "18  Spreadsheets",
    "section": "18.2 Formatting",
    "text": "18.2 Formatting\nWhen saving Excel workbooks, you can also leverage the “openxlsx” library to format and add formulas to your workbook. Let’s use the iris dataset to demonstrate these capabilities.\n\nlibrary(openxlsx)\n\nNext, let’s break down the iris dataset into three separate datasets based on species.\n\nsetosa <- iris[which(iris$\"Species\" == \"setosa\"),]\nversicolor <- iris[which(iris$\"Species\" == \"versicolor\"),]\nvirginica <- iris[which(iris$\"Species\" == \"virginica\"),]\n\nNow, we’ll use the “createWorkbook” function from the “openxlsx” library to create a blank workbook object.\n\nwb <- createWorkbook()\n\nWe’ll now add three worksheets to our workbook. These worksheets will ultimately be tabs in our Excel workbook.\n\naddWorksheet(wb, \"Setosa\")\naddWorksheet(wb, \"Versicolor\")\naddWorksheet(wb, \"Virginica\")\n\nWe can also create styles to apply to our workbook. Let’s create a style for our headers as well as a style for the body of our data.\n\nheading <- createStyle(fontName = \"Segoe UI\"\n                        , fontSize = 12\n                        , fontColour = \"#FFFFFF\"\n                        , bgFill = \"#244062\"\n                        , textDecoration = \"bold\")\n\nbody <- createStyle(fontName = \"Segoe UI\", fontSize = 12)\n\nLet’s now apply our three datasets to the workbook object we previously created.\n\n# Write the setosa dataset to the \"Setosa\" worksheet\nwriteData(wb\n            , \"Setosa\"\n            , setosa\n            , startCol = 1\n            , startRow = 1\n            , rowNames = FALSE)\n\n# Write the versicolor dataset to the \"Versicolor\" worksheet\nwriteData(wb\n            , \"Versicolor\"\n            , versicolor\n            , startCol = 1\n            , startRow = 1\n            , rowNames = FALSE)\n\n# Write the virginica dataset to the \"Virginica\" worksheet\nwriteData(wb\n            , \"Virginica\"\n            , virginica\n            , startCol = 1\n            , startRow = 1\n            , rowNames = FALSE)\n\nNow let’s apply our styles to each worksheet.\n\n# Apply styles to \"Setosa\" worksheet\naddStyle(wb\n          , \"Setosa\"\n          , cols = 1:length(setosa)\n          , rows = 1\n          , style = heading\n          , gridExpand = TRUE)\n          \naddStyle(wb\n          , \"Setosa\"\n          , cols = 1:length(setosa)\n          , rows = 2:nrow(setosa)\n          , style = body\n          , gridExpand = TRUE)\n\n# Apply styles to \"Versicolor\" worksheet\naddStyle(wb\n          , \"Versicolor\"\n          , cols = 1:length(versicolor)\n          , rows = 1\n          , style = heading\n          , gridExpand = TRUE)\n\naddStyle(wb\n          , \"Versicolor\"\n          , cols = 1:length(versicolor)\n          , rows = 2:nrow(versicolor)\n          , style = body\n          , gridExpand = TRUE)\n\n# Apply styles to \"Virginica\" worksheet\naddStyle(wb\n          , \"Virginica\"\n          , cols = 1:length(virginica)\n          , rows = 1\n          , style = heading\n          , gridExpand = TRUE)\n\naddStyle(wb\n          , \"Virginica\"\n          , cols = 1:length(virginica)\n          , rows = 2:nrow(virginica)\n          , style = body\n          , gridExpand = TRUE)\n\nFinally, we will save our workbook to a file named “iris.xlsx”.\n\nsaveWorkbook(wb, \"iris.xlsx\", overwrite = TRUE)\n\nThis will result in a workbook that looks like the following image.\n\n\n\n\n\nThe full script is shown below.\n\nlibrary(openxlsx)\n\n# Create datasets\nsetosa <- iris[which(iris$\"Species\" == \"setosa\"),]\nversicolor <- iris[which(iris$\"Species\" == \"versicolor\"),]\nvirginica <- iris[which(iris$\"Species\" == \"virginica\"),]\n\n# Create workbook object\nwb <- createWorkbook()\n\n#Add worksheets\naddWorksheet(wb, \"Setosa\")\naddWorksheet(wb, \"Versicolor\")\naddWorksheet(wb, \"Virginica\")\n\n# Create Styles\nheading <- createStyle(fontName = \"Segoe UI\"\n                       , fontSize = 12\n                       , fontColour = \"#FFFFFF\"\n                       , bgFill = \"#244062\"\n                       , textDecoration = \"bold\")\n\nbody <- createStyle(fontName = \"Segoe UI\", fontSize = 12)\n\n# Write the setosa dataset to the \"Setosa\" worksheet\nwriteData(wb\n            , \"Setosa\"\n            , setosa\n            , startCol = 1\n            , startRow = 1\n            , rowNames = FALSE)\n\n# Write the versicolor dataset to the \"Versicolor\" worksheet\nwriteData(wb\n            , \"Versicolor\"\n            , versicolor\n            , startCol = 1\n            , startRow = 1\n            , rowNames = FALSE)\n\n# Write the virginica dataset to the \"Virginica\" worksheet\nwriteData(wb\n            , \"Virginica\"\n            , virginica\n            , startCol = 1\n            , startRow = 1\n            , rowNames = FALSE)\n\n# Apply styles to \"Setosa\" worksheet\naddStyle(wb\n          , \"Setosa\"\n          , cols = 1:length(setosa)\n          , rows = 1\n          , style = heading\n          , gridExpand = TRUE)\n\naddStyle(wb\n          , \"Setosa\"\n          , cols = 1:length(setosa)\n          , rows = 2:nrow(setosa)\n          , style = body\n          , gridExpand = TRUE)\n\n# Apply styles to \"Versicolor\" worksheet\naddStyle(wb\n          , \"Versicolor\"\n          , cols = 1:length(versicolor)\n          , rows = 1\n          , style = heading\n          , gridExpand = TRUE)\n\naddStyle(wb\n          , \"Versicolor\"\n          , cols = 1:length(versicolor)\n          , rows = 2:nrow(versicolor)\n          , style = body\n          , gridExpand = TRUE)\n\n# Apply styles to \"Virginica\" worksheet\naddStyle(wb\n          , \"Virginica\"\n          , cols = 1:length(virginica)\n          , rows = 1\n          , style = heading\n          , gridExpand = TRUE)\n\naddStyle(wb\n          , \"Virginica\"\n          , cols = 1:length(virginica)\n          , rows = 2:nrow(virginica)\n          , style = body\n          , gridExpand = TRUE)\n\nsaveWorkbook(wb, \"iris.xlsx\", overwrite = TRUE)\n\nYou may notice that this script is a little longer than it needs to be. Let’s try to simplify it with a loop.\nThe following script will accomplish the exact same thing as the first script.\n\nlibrary(openxlsx)\n\nsetosa <- iris[which(iris$\"Species\" == \"setosa\"),]\nversicolor <- iris[which(iris$\"Species\" == \"versicolor\"),]\nvirginica <- iris[which(iris$\"Species\" == \"virginica\"),]\n\nwb <- createWorkbook()\n\nheading <- createStyle(fontName = \"Segoe UI\"\n                       , fontSize = 12\n                       , fontColour = \"#FFFFFF\"\n                       , bgFill = \"#244062\"\n                       , textDecoration = \"bold\")\n\nbody <- createStyle(fontName = \"Segoe UI\", fontSize = 12)\n\ndatasets <- list(setosa, virginica, versicolor)\nworksheets <- c(\"Setosa\", \"Virginica\", \"Versicolor\")\n\nfor (i in 1:3) {\n  df <- as.data.frame(datasets[i])\n  addWorksheet(wb, worksheets[i])\n  writeData(wb\n              , worksheets[i]\n              , df\n              , startCol = 1\n              , startRow = 1\n              , rowNames = FALSE)\n  addStyle(wb\n            , worksheets[i]\n            , cols = 1:length(df)\n            , rows = 1\n            , style = heading\n            , gridExpand = TRUE)\n  addStyle(wb\n            , worksheets[i]\n            , cols = 1:length(df)\n            , rows = 2:nrow(df)\n            , style = body\n            , gridExpand = TRUE)\n}\n\nsaveWorkbook(wb, \"iris.xlsx\", overwrite = TRUE)"
  },
  {
    "objectID": "p5c1-spreadsheets.html#formulas",
    "href": "p5c1-spreadsheets.html#formulas",
    "title": "18  Spreadsheets",
    "section": "18.3 Formulas",
    "text": "18.3 Formulas\nIf we wanted to add another column to each of our worksheets that used an Excel formula to determine the ratio between the sepal length and the sepal width, we could use the “writeFormula” function to accomplish that.\nThe following example uses a loop that creates a formula for each row which divides the respective value in column A by the the respective value in column B. Next we add the heading style to the first row in column six and add a header named “Sepal.Ratio”. Finally, we write the formula vector to column six beginning on row 2.\n\nlibrary(openxlsx)\n\nsetosa <- iris[which(iris$\"Species\" == \"setosa\"),]\nversicolor <- iris[which(iris$\"Species\" == \"versicolor\"),]\nvirginica <- iris[which(iris$\"Species\" == \"virginica\"),]\n\nwb <- createWorkbook()\n\nheading <- createStyle(fontName = \"Segoe UI\"\n                       , fontSize = 12\n                       , fontColour = \"#FFFFFF\"\n                       , bgFill = \"#244062\"\n                       , textDecoration = \"bold\")\n\nbody <- createStyle(fontName = \"Segoe UI\", fontSize = 12)\n\ndatasets <- list(setosa, virginica, versicolor)\nworksheets <- c(\"Setosa\", \"Virginica\", \"Versicolor\")\n\nfor (i in 1:3) {\n  df <- as.data.frame(datasets[i])\n  addWorksheet(wb, worksheets[i])\n  writeData(wb\n            , worksheets[i]\n            , df\n            , startCol = 1\n            , startRow = 1\n            , rowNames = FALSE)\n  addStyle(wb\n            , worksheets[i]\n            , cols = 1:length(df)\n            , rows = 1\n            , style = heading\n            , gridExpand = TRUE)\n  addStyle(wb\n            , worksheets[i]\n            , cols = 1:length(df)\n            , rows = 2:nrow(df)\n            , style = body\n            , gridExpand = TRUE)\n  \n  formula <- c()\n  \n  for (x in 2:(nrow(df) + 1)) {\n    formula <- append(formula, paste(\"A\", x, \"/B\", x, sep = ''))\n  }\n\n  addStyle(wb\n            , worksheets[i]\n            , cols = 6\n            , rows = 1\n            , style = heading\n            , gridExpand = TRUE)\n  writeData(wb\n              , worksheets[i]\n              , \"Sepal.Ratio\"\n              , startCol = 6\n              , startRow = 1\n              , rowNames = FALSE)\n  writeFormula(wb\n                , worksheets[i]\n                , formula\n                , startCol = 6\n                , startRow = 2)\n\n}\n\nsaveWorkbook(wb, \"iris.xlsx\", overwrite = TRUE)\n\nThis gives us an Excel workbook that looks like the following image."
  },
  {
    "objectID": "p5c1-spreadsheets.html#resources",
    "href": "p5c1-spreadsheets.html#resources",
    "title": "18  Spreadsheets",
    "section": "18.4 Resources",
    "text": "18.4 Resources\n\nopenxlsx documentation: https://cran.r-project.org/web/packages/openxlsx/openxlsx.pdf"
  },
  {
    "objectID": "p5c2-r-markdown.html#format-options",
    "href": "p5c2-r-markdown.html#format-options",
    "title": "19  R Markdown",
    "section": "19.1 Format Options",
    "text": "19.1 Format Options\nWe’ll begin by creating a new document by selecting the “New File” button towards the top left corner of R Studio and choosing “R Markdown” from the dropdown menu.\n\n\n\n\n\nThis will display a menu that looks like the following image.\n\n\n\n\n\nYou’ll notice that you have four main options on the left-hand side: “Document”, “Presentation”, “Shiny”, and “From Template”.\n\n\n\n\n\nEach of these options will have several sub-options. The “Document” option, for example is selected by default and you can see there are three sub-options on the right-hand side: “HTML”, “PDF”, and “Word”.\n\n\n\n\n\nThe “Presentation” option allows you to create slide-based presentations in either HTML, PDF, or PowerPoint format.\n\n\n\n\n\nThe “Shiny” option allows you to create either presentations or documents which include interactive Shiny components.\n\n\n\n\n\nFinally, the “From Template” option will display several options for you to leverage pre-made templates."
  },
  {
    "objectID": "p5c2-r-markdown.html#html-document-example",
    "href": "p5c2-r-markdown.html#html-document-example",
    "title": "19  R Markdown",
    "section": "19.2 HTML Document Example",
    "text": "19.2 HTML Document Example\nLet’s choose the HTML sub-option from the Document option and select “OK”.\n\n\n\n\n\nThis will result in a new file in your source pane that looks similar to the following image.\n\n\n\n\n\nYou can either continue to edit your document with markdown code or you can select the “visual” option towards the top-left corner of the source pane to have more of a traditional text editor experience.\n\n\n\n\n\nFinally, we can render our document by selecting the “knit” button.\n\n\n\n\n\nSelecting this will prompt you to save your file. After you do so, your rendered document will appear in your viewer tab.\n\n\n\n\n\nIn addition to the preview being displayed in your viewer tab, you should now also have an HTML file located in the same place as you saved your R Markdown file. You can select this file to preview it in your browser as well as send it to others for them to preview."
  },
  {
    "objectID": "p5c2-r-markdown.html#r-notebook",
    "href": "p5c2-r-markdown.html#r-notebook",
    "title": "19  R Markdown",
    "section": "19.3 R Notebook",
    "text": "19.3 R Notebook\nAnother subset of R Markdown is R Notebooks. There is a lot of crossover between regular R Markdown documents and R Notebooks; however, R notebooks will generally be used for more technical audiences such as other R users or even just to organize your own thought processes while coding.\nLet’s try creating a notebook by selecting the “New File” button towards the top left corner of R Studio and choosing “R Notebook” from the dropdown menu.\n\n\n\n\n\nThis will generate a new file in your source pane that looks like the following image.\n\n\n\n\n\nYou’ll notice that there is no “knit” option like there is in an ordinary R Markdown file. This is because this file is meant to be shared in its current format rather than as a rendered document. The “knit” option is replaced by a “preview” option. Selecting this option will result in the following output.\n\n\n\n\n\nThis generates a preview of your file in the viewer tab. You may also notice that the output of the plot(cars) code has not been rendered in the preview. This is because code has to be explicitly run in R Notebooks in order for it to be displayed in the rendered preview.\nLet’s run the code by pressing the green play button inside the code chunk.\n\n\n\n\n\nNow if you preview the notebook again you’ll see the plot output included."
  },
  {
    "objectID": "p5c2-r-markdown.html#resources",
    "href": "p5c2-r-markdown.html#resources",
    "title": "19  R Markdown",
    "section": "19.4 Resources",
    "text": "19.4 Resources\n\n“Document Templates” from “R Markdown: The Definitive Guide”: https://bookdown.org/yihui/rmarkdown/document-templates.html?version=2022.07.2%2B576&mode=desktop\nR Markdown Formats: https://rmarkdown.rstudio.com/formats.html\nR Markdown Home Page: https://rmarkdown.rstudio.com/\nR Markdown Notebooks: https://rmarkdown.rstudio.com/lesson-10.html"
  },
  {
    "objectID": "p5c3-r-shiny.html#quickstart",
    "href": "p5c3-r-shiny.html#quickstart",
    "title": "20  R Shiny",
    "section": "20.1 Quickstart",
    "text": "20.1 Quickstart\nLet’s create a new project containing a shiny application. Projects allow you to bundle multiple files into a a single workspace. You can create a new project via the “Create a new project” button towards the top left corner in RStudio.\n\n\n\n\n\nSince we are starting this project from scratch, let’s choose the “New Directory” option.\n\n\n\n\n\nNow you can see there are many types of projects that you can create (not just Shiny Applications). However, we are going to choose “Shiny Application” for this example.\n\n\n\n\n\nThis is going to create a new folder containing your project files. Choose what you would like to name that folder and where you would like for it to be saved.\n\n\n\n\n\nIf you’re working in RStudio, you should now have a sample application in your source pane. We’ll go more in depth into what all of this means later.\n\n\n\n\n\nFor now, let’s demo what this app looks like by pressing the “Run App” button towards the top right corner of your source pane. You should see a screen pop up that looks like this.\n\n\n\n\n\nWe can see that the application is using the faithful dataset to create a histogram which accepts user input to dynamically adjust the number of bins presented in the histogram."
  },
  {
    "objectID": "p5c3-r-shiny.html#basic-components-of-a-shiny-application",
    "href": "p5c3-r-shiny.html#basic-components-of-a-shiny-application",
    "title": "20  R Shiny",
    "section": "20.2 Basic Components of a Shiny Application",
    "text": "20.2 Basic Components of a Shiny Application\nShiny applications consist of two main components: a server function and a UI object. The server function will handle any logic you need to put into your application while the UI object will create a user interface. Additionally, you will need to include the “shiny” library and any other libraries that you use in your code. Let’s break down everything that is happening in this sample application\n\n20.2.1 Libraries\nOne library you will always need to include in your shiny applications is the “shiny” library. Make sure you include any other libraries you plan on using in your code.\n\nlibrary(shiny)\n\n\n\n20.2.2 UI\nThe next thing we see in our code is the creation of our UI object. This is where the application layout is created. The first function is the “fluidPage” function. This is probably one of the most common ways to create user interfaces in shiny applications. Layouts created with the fluid page methodology are organized into rows and columns and scale to fit varying browser sizes.\nThe “titlePanel” function creates a panel with your title inside of it. In our case, this function is responsible for “Old Faithful Geyser Data” being displayed at the top of the page.\nNext, we see the “sidebarLayout” function. This is essentially a pre-constructed layout which consists of a “sidebar” panel and a “main” panel which are created using the “sidebarPanel” and “mainPanel” functions, respectively. You’ll notice that our sidebar is actually located above our main panel rather than to the side. This is just because the size of our browser was small enough that they collapsed to be stacked on top of each other. If you increase the size of your browser, you will see the sidebar return to it’s original location.\nInside of the “sidebarPanel” function, we have a function called “sliderInput”. The “sliderInput” function creates the component which allows the user to select the number of bins in our app. We can see this function gives the component the name “bins”, the title “Number of Bins”, a minimum input of “1”, a maximum value of “50”, and a default value of “30”.\nThe last component of our UI object is the “mainPanel” function. This main panel designates the section where our output plot will ultimately go as can be observed by the “plotOutput” function nested inside of it. This “plotOutput” function is given the name “distPlot”. This is done so that it can be referenced later in our server function.\n\nui <- fluidPage(\n\n    # Application title\n    titlePanel(\"Old Faithful Geyser Data\"),\n\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"bins\",\n                        \"Number of bins:\",\n                        min = 1,\n                        max = 50,\n                        value = 30)\n        ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"distPlot\")\n        )\n    )\n)\n\n\n\n20.2.3 Server\nAfter we create the UI object, we’ll need to create our server function. We’ll pass two arguments into the function: “input” and “output”. The input argument allows us to access data from the user interface while the output argument allows us to pass data back to the user interface.\nInside the function, we reference the “distPlot” component of the UI by typing “output$distPlot”. After this, we pass a plot to the UI with the “renderPlot” function.\n\n\n\n\n\n\nNote\n\n\n\nThe UI can only accept the plot we are going to send it because it is using the “plotOutput” function. If you were going to send a different form of data, the UI would need to have the corresponding function in order to accept it.\nFor example, if your server was going to send a table to the UI your server would need to use the “renderTable” function and your UI would need to use the “tableOutput” function.\n\n\n\nserver <- function(input, output) {\n\n    output$distPlot <- renderPlot({\n        # generate bins based on input$bins from ui.R\n        x    <- faithful[, 2]\n        bins <- seq(min(x), max(x), length.out = input$bins + 1)\n\n        # draw the histogram with the specified number of bins\n        hist(x, breaks = bins, col = 'darkgray', border = 'white',\n             xlab = 'Waiting time to next eruption (in mins)',\n             main = 'Histogram of waiting times')\n    })\n}\n\n\n\n20.2.4 Putting it Together\nFinally, you will combine your server and your UI and actually run your app with the “shinyApp” function.\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "p5c3-r-shiny.html#deploying-application",
    "href": "p5c3-r-shiny.html#deploying-application",
    "title": "20  R Shiny",
    "section": "20.3 Deploying Application",
    "text": "20.3 Deploying Application\nNow that you’ve built an application, you can actually deploy it for the whole world to see. There are many ways to do this; however, probably the easiest way to get started is to create a free account with ShinyApps.io.\n\n20.3.1 ShinyApps.io\nNavigate to https://www.shinyapps.io/, select the “Sign Up” button and follow the steps to create a free account.\n\n\n\n\n\nOnce you create your account and see your dashboard, you can navigate to your “tokens” by selecting your name in the top right corner and choosing “tokens” from the dropdown menu.\n\n\n\n\n\nChoose the green “Add Token” button to create a new token.\n\n\n\n\n\nNow that your token has been generated, select the blue “Show” button to view it.\n\n\n\n\n\nYou should now have a window that resembles the following image. Select the “Show secret” button and then copy the code to your clipboard for use later.\n\n\n\n\n\n\n\n20.3.2 Configuring Account\nThe next thing we’ll need to do is to link RStudio to your ShinyApps.io account. You can do this by navigating back to RStudio and choosing the dropdown menu next to the publish button. From here, select the “Manage Accounts” option.\n\n\n\n\n\nYou’ll then get a window the resembles the following image. Choose the “Connect” button to continue.\n\n\n\n\n\nNext, you’ll see the following options. Choose “ShinyApps.io” to continue.\n\n\n\n\n\nNow you’ll have the oppportunity to paste your token from you ShinyApps.io account. After you do so, press the “Connect Account” button.\n\n\n\n\n\nNow that RStudio is linked to your ShinyApps.io account, you can press the publish button. You’ll then get a window which allows you to name your app before publishing. Once you are satisfied with the name you choose, select “Publish”.\n\n\n\n\n\nAfter a few moments, your browser should launch displaying your newly created Shiny App!"
  },
  {
    "objectID": "p5c3-r-shiny.html#resources",
    "href": "p5c3-r-shiny.html#resources",
    "title": "20  R Shiny",
    "section": "20.4 Resources",
    "text": "20.4 Resources\n\nShiny Home Page: https://shiny.rstudio.com/\nShiny UI Editor: https://rstudio.github.io/shinyuieditor/"
  },
  {
    "objectID": "p5exercises.html#questions",
    "href": "p5exercises.html#questions",
    "title": "Exercises",
    "section": "Questions",
    "text": "Questions\n\n\n\n\n\n\nExercise: 18-A\n\n\n\nWrite the first seven rows of the “faithful” dataset to a csv file named “faithful.csv”. Make sure you do not include any row names in your output file.\n\n\n\n\n\n\n\n\nExercise: 18-B\n\n\n\nWrite the entire “faithful” dataset to an xlsx file using the “saveWorkbook” function. Name the tab (worksheet) that the data is on “data” and make the text in the header row bold."
  },
  {
    "objectID": "p5exercises.html#answers",
    "href": "p5exercises.html#answers",
    "title": "Exercises",
    "section": "Answers",
    "text": "Answers\n\n\n\n\n\n\nAnswer: 18-A\n\n\n\nYou can accomplish this through the use of the “write.csv” function.\nwrite.csv(head(faithful, 7), \"faithful.csv\", row.names = FALSE)\n\n\n\n\n\n\n\n\nAnswer: 18-B\n\n\n\nThe following code will allow you to accomplish this task.\nlibrary(openxlsx)\nwb <- createWorkbook()\nheading <- createStyle(textDecoration = \"bold\")\naddWorksheet(wb, \"data\")\nwriteData(wb\n            , \"data\"\n            , faithful\n            , startCol = 1\n            , startRow = 1\n            , rowNames = FALSE)\naddStyle(wb\n            , \"data\"\n            , cols = 1:length(faithful)\n            , rows = 1\n            , style = heading\n            , gridExpand = TRUE)\nsaveWorkbook(wb, \"faithful.xlsx\", overwrite = TRUE)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chambers, Cleveland, J. M., and P. A. Tukey. 1983. Graphical Methods\nfor Data Analysis. Wadsworth & Brooks/Cole.\n\n\nEremenko, Kirill. 2020. “Hadley Wickham Talks Integration and\nFuture of r and Python [Audio Podcast].” SuperDataScience. https://www.superdatascience.com/podcast/hadley-wickham-talks-integration-and-future-of-python-and-r.\n\n\nGarvin, David A. 1993. “Building a Learning Organization.”\nHarvard Business Review July-August 1993.\n\n\nHermans, Felienne. 2021. “Hadley Wickham on r and Tidyverse [Audio\nPodcast].” Software Engineering Radio. https://www.se-radio.net/2021/03/episode-450-hadley-wickham-on-r-and-tidyverse/.\n\n\nHofmann, J. R. 1996. Enlightenment and Electrodynamics.\nCambridge University Press.\n\n\nIhaka, Ross. 1998. “R : Past and Future History.” https://www.stat.auckland.ac.nz/~ihaka/downloads/Interface98.pdf.\n\n\nMcCandless, David. 2010. “The Beauty of Data\nVisualization.” https://www.ted.com/talks/david_mccandless_the_beauty_of_data_visualization/transcript?language=en.\n\n\nPaulson, Josh. 2022. Navigating Code in the RStudio IDE. https://support.rstudio.com/hc/en-us/articles/200710523-Navigating-Code-in-the-RStudio-IDE."
  }
]